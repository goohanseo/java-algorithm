{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1EyRyNQIQcMX8MvAVkl9Z2zXRkCmEzHS_","timestamp":1680759105011}]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"markdown","source":["# Writing `ResNet` from Scratch in PyTorch\n","\n"],"metadata":{"id":"R5dbDkx70lCX"}},{"cell_type":"markdown","source":["이 강좌는 [이 블로그](https://blog.paperspace.com/writing-resnet-from-scratch-in-pytorch/)의 내용을 번역하고 부분적으로 수정한 것이다.\n","\n","Resnet은 Residual Connections의 개념을 도입하여 네트워크가 너무 깊을 경우 네트워크 성능이 저하되는 문제를 해결한 Computer Vision의 주요 혁신중 하나이다.\n","우선 ResNet의 아키텍처와 그 뒤에 숨어있는 직관적인 아이디어를 살펴보는 것으로 시작한다.\n","\n"],"metadata":{"id":"WozRbNY50-1t"}},{"cell_type":"markdown","source":["## Residual Block과 `Resnet`"],"metadata":{"id":"vzXMRHMm2Shi"}},{"cell_type":"markdown","source":["Resnet의 핵심 구성요소는 resudual block이다. 아래 그림이 하나의 residual block을 보여준다."],"metadata":{"id":"r5s_6pGBiuMe"}},{"cell_type":"markdown","source":["\n","\n","<img src=\"https://raw.githubusercontent.com/ohheum/DS2022/7ef336792c0a4ae3044653a7e020818354656b55/assets/image-9.png\" width=\"600\" height=\"360\">\n","\n","\n","\n"],"metadata":{"id":"KlEwVGZz2VkS"}},{"cell_type":"markdown","source":["위의 그림에서 보이듯이 순차적인 연결 외에 모델의 일부 계층을 건너뛰는 연결(skipped connection)이 있다. 건너뛰기 연결이 없을 때 이 모델이 학습해야할 매핑을 `H(x)`라고 한다면 건너뛰기 연결을 추가할 경우 순차 연결 부분이 학습해야할 매핑은 `F(x) = H(x) - x`가 될 것이다. 이 잔여(residual) 매핑  `F(x)`를 학습하는 것이 원래의 매핑 `H(x)`를 학습하는 것보다 쉽다. (극단적인 예로 `H(x)`가 identity mapping이라면 residual mapping F(x)는 zero mapping이다. identity mapping보다는 zero mapping이 학습하기 쉬울 것이다.)\n","\n","아래는 34 레이어 ResNet의 아키텍처입니다."],"metadata":{"id":"JVvyo-S74fwf"}},{"cell_type":"markdown","source":["<img src=\"https://raw.githubusercontent.com/ohheum/DS2022/7ef336792c0a4ae3044653a7e020818354656b55/assets/image-10.png\" width=\"800\" height=\"1800\">"],"metadata":{"id":"tjNFuA564Y4e"}},{"cell_type":"markdown","source":["## Dataset"],"metadata":{"id":"lwXbI5YL4lY1"}},{"cell_type":"markdown","source":["CIFAR-10 데이터 세트를 사용한다. CIFAR-10 데이터 세트는 10개 클래스의 60000개의 32x32 컬러 이미지로 구성되며 클래스당 6000개의 이미지가 있다. 50000개의 훈련 이미지와 10000개의 테스트 이미지가 있다.\n","\n","데이터 세트는 각각 10000개의 이미지가 있는 5개의 훈련 배치와 1개의 테스트 배치로 나뉜다. 테스트 배치에는 각 클래스에서 무작위로 선택된 정확히 1000개의 이미지가 포함된다. 학습 배치에는 나머지 이미지가 무작위 순서로 포함되지만 일부 학습 배치에는 한 클래스의 이미지가 다른 클래스보다 더 많을 수 있다. "],"metadata":{"id":"5UCTxdK34nQm"}},{"cell_type":"markdown","source":["<img src=\"https://pytorch.org/tutorials/_images/cifar10.png\" width=\"600\" height=\"420\">"],"metadata":{"id":"jWr1MnUY4uqu"}},{"cell_type":"markdown","source":["## Importing the Libraries"],"metadata":{"id":"pd1kloIX48Qm"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"3x85MEgYZcvr","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1680563685449,"user_tz":-540,"elapsed":8373,"user":{"displayName":"권오흠","userId":"05475008821310211864"}},"outputId":"e0ecba8c-3664-403e-c954-5e2a326f726d"},"outputs":[{"output_type":"stream","name":"stdout","text":["cuda\n"]}],"source":["import numpy as np\n","import torch\n","import torch.nn as nn\n","from torchvision import datasets\n","from torchvision import transforms\n","from torch.utils.data.sampler import SubsetRandomSampler\n","\n","\n","# Device configuration\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print(device)"]},{"cell_type":"markdown","source":["## Loading the Dataset"],"metadata":{"id":"M-phgx7a5AMU"}},{"cell_type":"markdown","source":["토치비전 라이브러리를 사용하여 데이터 세트를 로드한다."],"metadata":{"id":"xjTM5TIC5DsB"}},{"cell_type":"markdown","source":["* 아래의의 `data_loader` 함수는 트레이닝 데이터와 테스트 데이터에 대한 `DataLoader`를 생성하여 반환한다. \n","* 데이터 세트의 각 채널(빨간색, 녹색 및 파란색)의 평균 및 표준 편차로 정규화를 수행한다.\n","* 데이터 로더를 사용하면 데이터를 일괄적으로 반복할 수 있으며 데이터는 반복하는 동안 로드되며 시작 시 한 번에 모두 RAM에 로드되지는 않는다. 이것은 대규모 데이터 세트를 처리하는 경우 매우 유용하다.\n","* 매개변수 `test=False`인 경우 트레이닝 분할을, `test=True`인 경우 테스트 분할을 로드한다. train의 경우 분할은 무작위로 train과 validation set(0.9:0.1)으로 나뉜다."],"metadata":{"id":"VyT0X42N5OVA"}},{"cell_type":"code","source":["def data_loader(data_dir,\n","                batch_size,\n","                random_seed=42,\n","                valid_size=0.1,\n","                shuffle=True,\n","                test=False):\n","  \n","    normalize = transforms.Normalize(\n","        mean=[0.4914, 0.4822, 0.4465],\n","        std=[0.2023, 0.1994, 0.2010],\n","    )\n","\n","    # define transforms\n","    #이미지 변환 적용 이미지 크기를 224*224 픽셀로 조정, 픽셀 값 pytorch 텐서로 변환,\n","    #미리 계산된 평균과 표준 편차 값을 기반으로 정규화\n","    transform = transforms.Compose([\n","            transforms.Resize((224,224)),\n","            transforms.ToTensor(),\n","            normalize,\n","    ]\n","    #test true일 경우 함수는 cifar10 테스트 세트에 대한 dataloader 생성\n","    #아니면 훈련 및 검증 세트에 대한 dataloader 생성\n","    if test:\n","        dataset = datasets.CIFAR10(\n","          root=data_dir, train=False,\n","          download=True, transform=transform,\n","        )\n","\n","        data_loader = torch.utils.data.DataLoader(\n","            dataset, batch_size=batch_size, shuffle=shuffle\n","        )\n","\n","        return data_loader\n","\n","    # load the dataset\n","    train_dataset = datasets.CIFAR10(\n","        root=data_dir, train=True,\n","        download=True, transform=transform,\n","    )\n","\n","    valid_dataset = datasets.CIFAR10(\n","        root=data_dir, train=True,\n","        download=True, transform=transform,\n","    )\n","\n","    num_train = len(train_dataset)\n","    indices = list(range(num_train))\n","    split = int(np.floor(valid_size * num_train))\n","\n","    if shuffle:\n","        np.random.seed(42)\n","        np.random.shuffle(indices)\n","\n","    train_idx, valid_idx = indices[split:], indices[:split]\n","    train_sampler = SubsetRandomSampler(train_idx)\n","    valid_sampler = SubsetRandomSampler(valid_idx)\n","\n","    train_loader = torch.utils.data.DataLoader(\n","        train_dataset, batch_size=batch_size, sampler=train_sampler)\n"," \n","    valid_loader = torch.utils.data.DataLoader(\n","        valid_dataset, batch_size=batch_size, sampler=valid_sampler)\n","\n","    return (train_loader, valid_loader)\n","\n","\n","# CIFAR10 dataset \n","train_loader, valid_loader = data_loader(data_dir='./data',\n","                                         batch_size=64)\n","\n","test_loader = data_loader(data_dir='./data',\n","                              batch_size=64,\n","                              test=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PfiQ5edcZvVi","executionInfo":{"status":"ok","timestamp":1680563702264,"user_tz":-540,"elapsed":6879,"user":{"displayName":"권오흠","userId":"05475008821310211864"}},"outputId":"120b99d1-976e-4580-c748-2fdf94061639"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 170498071/170498071 [00:02<00:00, 70427352.04it/s] \n"]},{"output_type":"stream","name":"stdout","text":["Extracting ./data/cifar-10-python.tar.gz to ./data\n","Files already downloaded and verified\n","Files already downloaded and verified\n"]}]},{"cell_type":"markdown","source":["네, 맞습니다. Validation set과 Test set은 다릅니다. 머신러닝 프로젝트에서 데이터는 일반적으로 세 가지로 나누어집니다: Training set, Validation set, 그리고 Test set.\n","\n","Training set: 이 데이터셋은 모델을 훈련하는데 사용됩니다. 훈련 과정에서 모델은 입력 데이터와 관련된 가중치를 조정하여 예상되는 출력과 실제 출력 간의 오차를 최소화하려고 합니다.\n","\n","Validation set: 이 데이터셋은 모델의 성능을 검증하는데 사용됩니다. 훈련 과정에서 하이퍼파라미터를 조정하거나, 여러 모델 구조를 비교하여 가장 좋은 성능을 내는 모델을 선택할 때 이 데이터셋이 사용됩니다. 이를 통해 모델이 과적합되지 않고 일반화 성능이 좋은지 확인할 수 있습니다.\n","\n","Test set: 이 데이터셋은 모델의 최종 성능을 평가하는데 사용됩니다. Validation set을 통해 하이퍼파라미터를 조정하고 최적의 모델을 선택한 후, 이 최종 테스트 데이터셋을 사용하여 모델이 실제로 예측할 때 얼마나 잘 수행되는지 확인할 수 있습니다. 테스트 데이터셋은 모델 훈련 및 검증 과정에서 사용되지 않으며, 오직 최종 성능 평가에만 사용됩니다.\n","\n","(0.9:0.1)로 데이터를 나눈다는 것은 전체 데이터의 90%를 훈련 데이터로 사용하고, 10%를 검증 데이터로 사용한다는 의미입니다. 이 경우, 테스트 데이터셋은 별도로 준비되어야 합니다. 이렇게 하면 모델이 과적합되지 않고 일반화 성능이 좋은지 확인할 수 있습니다."],"metadata":{"id":"ZsiI5JJQnDov"}},{"cell_type":"markdown","source":["## How models work in PyTorch"],"metadata":{"id":"Ur-7NAIm5gDW"}},{"cell_type":"markdown","source":[" ResNet에는 PyTorch가 제공하는 다양한 유형의 레이어가 사용된다.\n","\n","* nn.Conv2d: 커널 크기와 함께 입력 및 출력 채널의 수를 인수로 받아들이는 컨볼루션 계층. \n","* nn.BatchNorm2d: 컨볼루션 레이어의 출력에 **배치 정규화**를 적용\n","* nn.ReLU: 네트워크의 다양한 출력에 적용되는 활성화 함수\n","* nn.MaxPool2d : 최대 풀링을 적용\n","* nn.Dropout: 주어진 확률로 출력에 **드롭아웃**을 적용\n","* nn.Linear: 완전히 연결된 레이어\n","* nn.Sequential: 여러 계층을 결합하는데 사용됨"],"metadata":{"id":"q6u8780k5jc2"}},{"cell_type":"markdown","source":["#### 배치정규화(BatchNormalization)"],"metadata":{"id":"VkG929WwMMTq"}},{"cell_type":"markdown","source":["배치 정규화는 레이어의 입력을 다시 중심을 잡고(re-centering) 크기를 조정하여(re-scaling) 정규화함으로써 신경망의 학습을 더 빠르고 안정적으로 만드는 데 사용되는 방법이다. 2015년 Sergey Ioffe와 Christian Szegedy가 [제안](https://arxiv.org/pdf/1502.03167.pdf)하였다.\n","\n","배치 정규화가 효과가 있다는 사실은 비교적 분명하지만, 그 이유는 아직 논의 중이다. 배치 정규화가 각 계층의 파라미터 초기화와 입력 분포 변화가 네트워크의 학습 속도에 영향을 미치는 내부 공변량 이동 문제(internal covariate shift problem)를 완화할 수 있다고 믿어져 왔으나 \n","최근 일부 학자들은 배치 정규화가 내부 공변량 이동을 줄이는 것이 아니라 오히려 목적 함수를 평활화하여(smoothing) 성능을 향상시킨다고 주장하고 있다. \n","\n","> <img src=\"https://raw.github.com/ohheum/DS2022/90abb607bd93581c26f729e51d95cd1fdc6982b9/assets/batch_norm.png\" width=\"600\" height=\"460\">"],"metadata":{"id":"5l-t_MU8NszM"}},{"cell_type":"markdown","source":["#### 드랍아웃(Dropout)"],"metadata":{"id":"KYE6J1R5cfJ9"}},{"cell_type":"markdown","source":["과적합(overfitting)을 줄이기 위한 한 가지 방법은 동일한 데이터셋에 가능한 모든 서로 다른 신경망을 맞추고 각 모델의 예측을 평균하는 것이다. 실제로 이렇게 하는 것은 불가능하며 Dropout은 신경망에서 매 트레이닝 단계마다 일정 비율의 연결을 랜덤하게 drop하여 마치 동시에 서로 다른 여러 개의 네트워크를 트레이닝하는 것과 같은 효과를 기대하는 기법이다. \n","\n","> <img src=\"https://raw.github.com/ohheum/DS2022/1588b3936f3a10fb63a2bb451b6095d74ad21f22/assets/dropout.png\" width=\"600\" height=\"320\">\n"],"metadata":{"id":"1sf3QrNfdiek"}},{"cell_type":"markdown","source":["## Residual Block"],"metadata":{"id":"EqD9C1Qe5s3m"}},{"cell_type":"markdown","source":["먼저 네트워크 전체에서 재사용할 수 있는 `ResidualBlock`을 정의한다. \n","\n","<img src=\"https://raw.githubusercontent.com/ohheum/DS2022/7ef336792c0a4ae3044653a7e020818354656b55/assets/image-9.png\" width=\"600\" height=\"360\">\n"],"metadata":{"id":"OYFue1Gy5vJ2"}},{"cell_type":"code","source":["class ResidualBlock(nn.Module): #전체를 하나의 모듈로 만들어주는 클래스\n","#residual block:입력텐서 x를 받아 배치 정규화와 relue 활성화 적용한 후 두 개의 합성곱 연산 수행\n","#64채널 \n","#in_channel과 out_channel은 첫 번째 합성곱 연산의 입력 및 출력 채널 수를 지정\n","#stride 매개변수는 첫 번째 합성곱 연산의 스트라이드를 지정, 스트라이드는 입력 텐서의 다운샘플링 제어에 사용\n","#downsample은 입력 텐서의 공간 차원이 출력 텐서와 일치하지 않는 경우 다운샘플링에 사용되는 선택적인 1*1 합성곱 연산\n","    def __init__(self, in_channels, out_channels, stride = 1, downsample = None):\n","        super(ResidualBlock, self).__init__()\n","        self.conv1 = nn.Sequential(\n","                        nn.Conv2d(in_channels, out_channels, kernel_size = 3, stride = stride, padding = 1),\n","                        #kernel 1 stride 1 padding 1 사이즈 불변\n","                        nn.BatchNorm2d(out_channels),\n","                        nn.ReLU())\n","        #conv2의 출력은 입력 텐서x에 더해져 residual connection 형성\n","        self.conv2 = nn.Sequential(\n","                        nn.Conv2d(out_channels, out_channels, kernel_size = 3, stride = 1, padding = 1), #stride =1 -> 이 블럭 안에서 맵의 사이즈는 불변\n","                        nn.BatchNorm2d(out_channels))\n","        #선택적으로 1*1 합성곱 연산과 스트라이드사용하여 입력텐서 x를 다운샘플할수 있음\n","        #residual block에서 다운샘플링 수행하는 것은 입력 텐서의 공간 차원을 줄이면서도 입력\n","        #텐서의 채널 수를 변경하지 않고 유지할 수 있다\n","        #resnet 아키텍쳐에서 매우 중요하다. 이전의 딥러닝 아키텍쳐는 pooling 레이어 사용을 공간 크기 줄임\n","        #pooling레이어는 채널 수를 줄이는 단점이 있음\n","        self.downsample = downsample\n","        self.relu = nn.ReLU()\n","        #출력은 relu 활성화 함수를 통해 전달되며 redual block의 출력으로 반환\n","        self.out_channels = out_channels #최종적으로 나가는\n","    #residual block의 순방향 패스 정의\n","    #입력 텐서 x를 받아서 두 개의 합성곱 연산 수행 후 residual connection 형성    \n","    def forward(self, x): #변하지 않음 채널 갯수, 맵의 사이즈 변하지 않음\n","        residual = x\n","        out = self.conv1(x)\n","        out = self.conv2(out)\n","        if self.downsample:\n","            residual = self.downsample(x)\n","        out += residual\n","        out = self.relu(out)\n","        return out"],"metadata":{"id":"8HZ8Tb00ZzCJ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Resnet"],"metadata":{"id":"dMABgdVS51t9"}},{"cell_type":"markdown","source":["이제 `ResidualBlock`을 만들었으므로 ResNet을 빌드할 수 있다.\n","\n","아키텍처에는 각각 3, 4, 6, 3개의 레이어를 포함하는 4개의 블록이 있다. 이 블록들을 만들기 위해 도우미 함수 `_make_layer`를 만든다. 마지막으로로 평균 풀링(average pooling)과 최종 선형(linear) 레이어를 추가한다."],"metadata":{"id":"P4rV_1Og53Tu"}},{"cell_type":"code","source":["class ResNet(nn.Module):\n","   #입력 이미지 크기에 맞게 합성공 레이어와 residual block 레이어 구상하고 \n","   #이를 이어서 선형 레이어로 연결하여 최종 출렧 생성\n","    def __init__(self, block, layers, num_classes = 10):\n","        super(ResNet, self).__init__()\n","        #다음 block layer의 입력 채널 수 지정\n","        self.inplanes = 64    # num of input channels of the next residual block\n","        #7*7 커널 크기 사용하여 입력 이미지를 convolution 레이어로 인코딩, \n","        #3*3 커널 크기 사용하여 이미지 다운 샘플링\n","        #각 채널 정규화하기 위해 batch normalization 수행 후 relu 활성화 함수 적용\n","        self.conv1 = nn.Sequential(\n","                        nn.Conv2d(3, 64, kernel_size = 7, stride = 2, padding = 3),\n","                        nn.BatchNorm2d(64),\n","                        nn.ReLU())\n","        #3*3 커널 크기 사용하여 이미지 다운샘플링\n","        self.maxpool = nn.MaxPool2d(kernel_size = 3, stride = 2, padding = 1)\n","        #_make_layer 메서드 사용하여 블록 레이어 생성, \n","        #layers list는 각 residual block 당 블록 수를 저장\n","        #stride 인자는 다운샘플링에 사용되는 스트라이드 나타냄\n","        self.layer0 = self._make_layer(block, 64, layers[0], stride = 1)  \n","        self.layer1 = self._make_layer(block, 128, layers[1], stride = 2)\n","        self.layer2 = self._make_layer(block, 256, layers[2], stride = 2)\n","        self.layer3 = self._make_layer(block, 512, layers[3], stride = 2)\n","        #각 채널마다 특징 맵의 평균값을 계산하여 채널별로 하나의 값을 출력\n","        self.avgpool = nn.AvgPool2d(7, stride=1)\n","        #입력 텐서를 특정 클래스 수에 대한 확률 분포로 변환하는 선형레이어,num_classses 출력 클래스의 수를 지정\n","        self.fc = nn.Linear(512, num_classes)\n","    \n","    #block 클래스, 블록당 채널 수, 블록당 잔차 블록 수, 다운샘플링에 사용되는 스트라이드 값을 사용하여\n","    #residual block layer 생성\n","    def _make_layer(self, block, planes, blocks, stride=1):\n","        downsample = None\n","        #stride가 1이 아니거나 입력 채널 수가 출력 채널 수와 같지 않으면\n","        #downsample은 1*1 컨벌류션 레이어와 배치를 사용하여 생성\n","        if stride != 1 or self.inplanes != planes:\n","            \n","            downsample = nn.Sequential(\n","                nn.Conv2d(self.inplanes, planes, kernel_size=1, stride=stride),\n","                nn.BatchNorm2d(planes),\n","            )\n","        layers = []\n","        layers.append(block(self.inplanes, planes, stride, downsample))\n","        self.inplanes = planes\n","        for i in range(1, blocks):\n","            layers.append(block(self.inplanes, planes))\n","        # 레이어의 모든 잔여 블록을 포함하는 nn.Sequential 개체를 반환\n","        return nn.Sequential(*layers)\n","    \n","    #resnet 모델의 정방향 전달을 수행\n","    def forward(self, x):     # x.shape=(3,224,224)\n","    #입력이미지 x는 convolution, batch normalization 및 relu 활성화 수행하여\n","    #입력 이미지 인코딩하는 self.conv1 레이어 통과\n","        x = self.conv1(x)     # (64, 112, 112)\n","        #최대풀링 수행하여 기능 맵을 다운샘플링\n","        x = self.maxpool(x)   # (64, 56, 56)\n","        #생성된 4개의 잔여 블록 레이어(self.layer0~3) 각각을 통과\n","        x = self.layer0(x)    # (56, 56)\n","        x = self.layer1(x)    # (28, 28)\n","        x = self.layer2(x)    # (14, 14)\n","        x = self.layer3(x)    # (7, 7)\n","        #각 계층은 기능 맵의 공간 해상도를 점진적으로 줄이고 기능 채널 수를 늘림\n","        x = self.avgpool(x)   # (1,1)\n","        x = x.view(x.size(0), -1)   # 512\n","        #평명화된 특성 벡터는 self.fc를 통해 선형 변환을 수행하여 각 클래스의 확률을 나타내는 최종 출려 ㄱ벡터를 생성, 그 다음 출력반환\n","        x = self.fc(x)        \n","\n","        return x"],"metadata":{"id":"msVMW6gxZ4ap"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Setting Hyperparameters"],"metadata":{"id":"bIzlULci582f"}},{"cell_type":"code","source":["#Resnet 모델 교육을 위한 여러 하이퍼파라미터 정의\n","#cifar-10 데이터 세트 출력 클래스 수인 10 설정\n","num_classes = 10\n","#훈련 중 전체 데이터 세트가 모델을 통과하는 횟수인 20설정\n","num_epochs = 20\n","#각 학습 반복에서 사용도리 샘플 수인 16설정\n","batch_size = 16\n","#손실 함수 최소값을 향해 이동하면서 각 반복에서 단계 크기 결정\n","learning_rate = 0.01\n","#resnet 모델 생성\n","#4개의 residual block이 있는 resnet 모델 생성\n","#layer는 각순서대로 3,4,6,3개의 residual block을 포함\n","model = ResNet(ResidualBlock, [3, 4, 6, 3]).to(device) #16 레지듀얼 블럭\n","#매개변수의 수와 각 레이어의 출력 모양을 포함하여 모델 아키텍처의 요약을 인쇄\n","from torchsummary import summary\n","print(summary(model, (3, 224, 224)))\n","\n","# Loss and optimizer\n","#훈련 중 손실을 계산하는데 사용, 학습에 사용되는 옵티마이저는 확률적 옵티마이저 SGD\n","#모델 매개변수, 학습 속도, 가중치 감쇠 및 모멘텀을 인수로 사용\n","criterion = nn.CrossEntropyLoss()\n","optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, weight_decay = 0.001, momentum = 0.9)  \n","\n","# Train the model\n","#훈련 중에 수행될 총 반복 횟수를 결정하는데 사용\n","#train_loader는 학습 샘플 배치를 모델에 제공하는 pytorch 데이터로더\n","total_step = len(train_loader)"],"metadata":{"id":"QqURongpZ6e7","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1680131701394,"user_tz":-540,"elapsed":11267,"user":{"displayName":"권오흠","userId":"05475008821310211864"}},"outputId":"dc57d407-59a5-40ce-c774-3279718ec405"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1         [-1, 64, 112, 112]           9,472\n","       BatchNorm2d-2         [-1, 64, 112, 112]             128\n","              ReLU-3         [-1, 64, 112, 112]               0\n","         MaxPool2d-4           [-1, 64, 56, 56]               0\n","            Conv2d-5           [-1, 64, 56, 56]          36,928\n","       BatchNorm2d-6           [-1, 64, 56, 56]             128\n","              ReLU-7           [-1, 64, 56, 56]               0\n","            Conv2d-8           [-1, 64, 56, 56]          36,928\n","       BatchNorm2d-9           [-1, 64, 56, 56]             128\n","             ReLU-10           [-1, 64, 56, 56]               0\n","    ResidualBlock-11           [-1, 64, 56, 56]               0\n","           Conv2d-12           [-1, 64, 56, 56]          36,928\n","      BatchNorm2d-13           [-1, 64, 56, 56]             128\n","             ReLU-14           [-1, 64, 56, 56]               0\n","           Conv2d-15           [-1, 64, 56, 56]          36,928\n","      BatchNorm2d-16           [-1, 64, 56, 56]             128\n","             ReLU-17           [-1, 64, 56, 56]               0\n","    ResidualBlock-18           [-1, 64, 56, 56]               0\n","           Conv2d-19           [-1, 64, 56, 56]          36,928\n","      BatchNorm2d-20           [-1, 64, 56, 56]             128\n","             ReLU-21           [-1, 64, 56, 56]               0\n","           Conv2d-22           [-1, 64, 56, 56]          36,928\n","      BatchNorm2d-23           [-1, 64, 56, 56]             128\n","             ReLU-24           [-1, 64, 56, 56]               0\n","    ResidualBlock-25           [-1, 64, 56, 56]               0\n","           Conv2d-26          [-1, 128, 28, 28]          73,856\n","      BatchNorm2d-27          [-1, 128, 28, 28]             256\n","             ReLU-28          [-1, 128, 28, 28]               0\n","           Conv2d-29          [-1, 128, 28, 28]         147,584\n","      BatchNorm2d-30          [-1, 128, 28, 28]             256\n","           Conv2d-31          [-1, 128, 28, 28]           8,320\n","      BatchNorm2d-32          [-1, 128, 28, 28]             256\n","             ReLU-33          [-1, 128, 28, 28]               0\n","    ResidualBlock-34          [-1, 128, 28, 28]               0\n","           Conv2d-35          [-1, 128, 28, 28]         147,584\n","      BatchNorm2d-36          [-1, 128, 28, 28]             256\n","             ReLU-37          [-1, 128, 28, 28]               0\n","           Conv2d-38          [-1, 128, 28, 28]         147,584\n","      BatchNorm2d-39          [-1, 128, 28, 28]             256\n","             ReLU-40          [-1, 128, 28, 28]               0\n","    ResidualBlock-41          [-1, 128, 28, 28]               0\n","           Conv2d-42          [-1, 128, 28, 28]         147,584\n","      BatchNorm2d-43          [-1, 128, 28, 28]             256\n","             ReLU-44          [-1, 128, 28, 28]               0\n","           Conv2d-45          [-1, 128, 28, 28]         147,584\n","      BatchNorm2d-46          [-1, 128, 28, 28]             256\n","             ReLU-47          [-1, 128, 28, 28]               0\n","    ResidualBlock-48          [-1, 128, 28, 28]               0\n","           Conv2d-49          [-1, 128, 28, 28]         147,584\n","      BatchNorm2d-50          [-1, 128, 28, 28]             256\n","             ReLU-51          [-1, 128, 28, 28]               0\n","           Conv2d-52          [-1, 128, 28, 28]         147,584\n","      BatchNorm2d-53          [-1, 128, 28, 28]             256\n","             ReLU-54          [-1, 128, 28, 28]               0\n","    ResidualBlock-55          [-1, 128, 28, 28]               0\n","           Conv2d-56          [-1, 256, 14, 14]         295,168\n","      BatchNorm2d-57          [-1, 256, 14, 14]             512\n","             ReLU-58          [-1, 256, 14, 14]               0\n","           Conv2d-59          [-1, 256, 14, 14]         590,080\n","      BatchNorm2d-60          [-1, 256, 14, 14]             512\n","           Conv2d-61          [-1, 256, 14, 14]          33,024\n","      BatchNorm2d-62          [-1, 256, 14, 14]             512\n","             ReLU-63          [-1, 256, 14, 14]               0\n","    ResidualBlock-64          [-1, 256, 14, 14]               0\n","           Conv2d-65          [-1, 256, 14, 14]         590,080\n","      BatchNorm2d-66          [-1, 256, 14, 14]             512\n","             ReLU-67          [-1, 256, 14, 14]               0\n","           Conv2d-68          [-1, 256, 14, 14]         590,080\n","      BatchNorm2d-69          [-1, 256, 14, 14]             512\n","             ReLU-70          [-1, 256, 14, 14]               0\n","    ResidualBlock-71          [-1, 256, 14, 14]               0\n","           Conv2d-72          [-1, 256, 14, 14]         590,080\n","      BatchNorm2d-73          [-1, 256, 14, 14]             512\n","             ReLU-74          [-1, 256, 14, 14]               0\n","           Conv2d-75          [-1, 256, 14, 14]         590,080\n","      BatchNorm2d-76          [-1, 256, 14, 14]             512\n","             ReLU-77          [-1, 256, 14, 14]               0\n","    ResidualBlock-78          [-1, 256, 14, 14]               0\n","           Conv2d-79          [-1, 256, 14, 14]         590,080\n","      BatchNorm2d-80          [-1, 256, 14, 14]             512\n","             ReLU-81          [-1, 256, 14, 14]               0\n","           Conv2d-82          [-1, 256, 14, 14]         590,080\n","      BatchNorm2d-83          [-1, 256, 14, 14]             512\n","             ReLU-84          [-1, 256, 14, 14]               0\n","    ResidualBlock-85          [-1, 256, 14, 14]               0\n","           Conv2d-86          [-1, 256, 14, 14]         590,080\n","      BatchNorm2d-87          [-1, 256, 14, 14]             512\n","             ReLU-88          [-1, 256, 14, 14]               0\n","           Conv2d-89          [-1, 256, 14, 14]         590,080\n","      BatchNorm2d-90          [-1, 256, 14, 14]             512\n","             ReLU-91          [-1, 256, 14, 14]               0\n","    ResidualBlock-92          [-1, 256, 14, 14]               0\n","           Conv2d-93          [-1, 256, 14, 14]         590,080\n","      BatchNorm2d-94          [-1, 256, 14, 14]             512\n","             ReLU-95          [-1, 256, 14, 14]               0\n","           Conv2d-96          [-1, 256, 14, 14]         590,080\n","      BatchNorm2d-97          [-1, 256, 14, 14]             512\n","             ReLU-98          [-1, 256, 14, 14]               0\n","    ResidualBlock-99          [-1, 256, 14, 14]               0\n","          Conv2d-100            [-1, 512, 7, 7]       1,180,160\n","     BatchNorm2d-101            [-1, 512, 7, 7]           1,024\n","            ReLU-102            [-1, 512, 7, 7]               0\n","          Conv2d-103            [-1, 512, 7, 7]       2,359,808\n","     BatchNorm2d-104            [-1, 512, 7, 7]           1,024\n","          Conv2d-105            [-1, 512, 7, 7]         131,584\n","     BatchNorm2d-106            [-1, 512, 7, 7]           1,024\n","            ReLU-107            [-1, 512, 7, 7]               0\n","   ResidualBlock-108            [-1, 512, 7, 7]               0\n","          Conv2d-109            [-1, 512, 7, 7]       2,359,808\n","     BatchNorm2d-110            [-1, 512, 7, 7]           1,024\n","            ReLU-111            [-1, 512, 7, 7]               0\n","          Conv2d-112            [-1, 512, 7, 7]       2,359,808\n","     BatchNorm2d-113            [-1, 512, 7, 7]           1,024\n","            ReLU-114            [-1, 512, 7, 7]               0\n","   ResidualBlock-115            [-1, 512, 7, 7]               0\n","          Conv2d-116            [-1, 512, 7, 7]       2,359,808\n","     BatchNorm2d-117            [-1, 512, 7, 7]           1,024\n","            ReLU-118            [-1, 512, 7, 7]               0\n","          Conv2d-119            [-1, 512, 7, 7]       2,359,808\n","     BatchNorm2d-120            [-1, 512, 7, 7]           1,024\n","            ReLU-121            [-1, 512, 7, 7]               0\n","   ResidualBlock-122            [-1, 512, 7, 7]               0\n","       AvgPool2d-123            [-1, 512, 1, 1]               0\n","          Linear-124                   [-1, 10]           5,130\n","================================================================\n","Total params: 21,298,314\n","Trainable params: 21,298,314\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 0.57\n","Forward/backward pass size (MB): 96.28\n","Params size (MB): 81.25\n","Estimated Total Size (MB): 178.10\n","----------------------------------------------------------------\n","None\n"]}]},{"cell_type":"markdown","source":["## Training"],"metadata":{"id":"KwfVZC536C8-"}},{"cell_type":"code","source":["#resnet 모델의 교육 및 검증을 수행\n","import gc\n","total_step = len(train_loader)\n","#train_loader는 학습 샘플 배치를 모델에 제공하는 pytorch 데이터 로더\n","for epoch in range(num_epochs):\n","    for i, (images, labels) in enumerate(train_loader):  \n","        # Move tensors to the configured device\n","        images = images.to(device)\n","        labels = labels.to(device)\n","        # Forward pass\n","        # model(images)를 사용하여 이미지 resnet 모델에 전달하여 수행되며 \n","        # 손실은 criterion 사용하여 계산\n","        outputs = model(images)\n","        loss = criterion(outputs, labels)\n","        \n","        # Backward and optimize\n","        #옵티마이저 사용하여 그래디언트 역전파하고 모델 매개볂수 업데이트\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","        #메모리 누수를 방지하기 위해 임시변ㄴ수 imgaes,labels,output 메모리에서 삭제\n","        del images, labels, outputs\n","        #empty_cache, gc.collect 사용하여 gpu 캐시 지워짐\n","        torch.cuda.empty_cache()\n","        gc.collect()\n","\n","    print ('Epoch [{}/{}], Loss: {:.4f}' \n","                   .format(epoch+1, num_epochs, loss.item()))\n","            \n","    # Validation\n","    # 그래디언트가 계산되지 않도록 한다\n","    with torch.no_grad():\n","        correct = 0\n","        total = 0\n","        for images, labels in valid_loader:\n","            images = images.to(device)\n","            labels = labels.to(device)\n","            outputs = model(images)\n","            _, predicted = torch.max(outputs.data, 1)\n","            total += labels.size(0)\n","            correct += (predicted == labels).sum().item()\n","            del images, labels, outputs\n","    \n","        print('Accuracy of the network on the {} validation images: {} %'.format(5000, 100 * correct / total)) \n","#resnet 모델은 valid_loader의 각 유효성 검사 이미지에 대한 레이블을 예측하는데 사용        "],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Wr-1vzX5Z9XI","executionInfo":{"status":"ok","timestamp":1663058695436,"user_tz":-540,"elapsed":7228919,"user":{"displayName":"권오흠","userId":"05475008821310211864"}},"outputId":"87a0058b-cc94-4173-e291-ca9ee6a5c6a4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch [1/20], Loss: 1.7966\n","Accuracy of the network on the 5000 validation images: 58.34 %\n","Epoch [2/20], Loss: 1.1065\n","Accuracy of the network on the 5000 validation images: 73.26 %\n","Epoch [3/20], Loss: 0.8445\n","Accuracy of the network on the 5000 validation images: 77.04 %\n","Epoch [4/20], Loss: 0.4434\n","Accuracy of the network on the 5000 validation images: 76.18 %\n","Epoch [5/20], Loss: 0.7916\n","Accuracy of the network on the 5000 validation images: 80.78 %\n","Epoch [6/20], Loss: 1.1853\n","Accuracy of the network on the 5000 validation images: 79.86 %\n","Epoch [7/20], Loss: 0.5203\n","Accuracy of the network on the 5000 validation images: 82.94 %\n","Epoch [8/20], Loss: 0.4756\n","Accuracy of the network on the 5000 validation images: 83.4 %\n","Epoch [9/20], Loss: 0.8902\n","Accuracy of the network on the 5000 validation images: 82.74 %\n","Epoch [10/20], Loss: 0.6302\n","Accuracy of the network on the 5000 validation images: 83.6 %\n","Epoch [11/20], Loss: 0.0569\n","Accuracy of the network on the 5000 validation images: 84.52 %\n","Epoch [12/20], Loss: 0.7150\n","Accuracy of the network on the 5000 validation images: 83.48 %\n","Epoch [13/20], Loss: 1.1573\n","Accuracy of the network on the 5000 validation images: 83.98 %\n","Epoch [14/20], Loss: 0.1318\n","Accuracy of the network on the 5000 validation images: 83.74 %\n","Epoch [15/20], Loss: 0.7796\n","Accuracy of the network on the 5000 validation images: 83.32 %\n","Epoch [16/20], Loss: 0.1141\n","Accuracy of the network on the 5000 validation images: 83.38 %\n","Epoch [17/20], Loss: 0.3876\n","Accuracy of the network on the 5000 validation images: 84.36 %\n","Epoch [18/20], Loss: 0.1647\n","Accuracy of the network on the 5000 validation images: 83.06 %\n","Epoch [19/20], Loss: 0.5926\n","Accuracy of the network on the 5000 validation images: 83.74 %\n","Epoch [20/20], Loss: 0.4357\n","Accuracy of the network on the 5000 validation images: 83.52 %\n"]}]},{"cell_type":"markdown","source":["코드의 출력을 보면 매 에포크마다 검증(validation) 세트의 정확도가 증가하고 손실이 감소함에 따라 모델이 학습하고 있음을 알 수 있다. "],"metadata":{"id":"6DdUOW0j6QIg"}},{"cell_type":"markdown","source":["## Testing"],"metadata":{"id":"yyaey-7C6WG1"}},{"cell_type":"markdown","source":["테스트를 위해 유효성 검사와 정확히 동일한 코드를 사용하지만 test_loader를 사용한다."],"metadata":{"id":"scU8tvDD6XsU"}},{"cell_type":"code","source":["with torch.no_grad():\n","    correct = 0\n","    total = 0\n","    for images, labels in test_loader:\n","        images = images.to(device)\n","        labels = labels.to(device)\n","        outputs = model(images)\n","        _, predicted = torch.max(outputs.data, 1)\n","        total += labels.size(0)\n","        correct += (predicted == labels).sum().item()\n","        del images, labels, outputs\n","\n","    print('Accuracy of the network on the {} test images: {} %'.format(10000, 100 * correct / total))   "],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ve5OoeR6aKx5","executionInfo":{"status":"ok","timestamp":1663058727534,"user_tz":-540,"elapsed":32101,"user":{"displayName":"권오흠","userId":"05475008821310211864"}},"outputId":"465344b4-780f-4b2d-cc66-993fd83328ff"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy of the network on the 10000 test images: 83.93 %\n"]}]},{"cell_type":"markdown","source":["\n","위의 코드를 사용하고 10개의 에포크 동안 모델을 훈련하여 테스트 세트에서 82.87%의 정확도를 달성할 수 있었다."],"metadata":{"id":"2JULaEu1g01L"}},{"cell_type":"markdown","source":["# `torchvision.models.resnet`"],"metadata":{"id":"57cV-Kt8n8cP"}},{"cell_type":"markdown","source":["`torchvision`은 다양한 버전의 트레이닝된 `resnet`을 제공한다. `torchvision`이 제공하는 `resnet`의 목록은 [여기](https://pytorch.org/vision/main/models/resnet.html)에서 확인하라. 이하에서는 그 중에서 가장 작은 규모인 [`resnet18`](https://pytorch.org/vision/main/models/generated/torchvision.models.resnet18.html#torchvision.models.resnet18)을 사용해보자."],"metadata":{"id":"_AKwPp1yoOZ_"}},{"cell_type":"code","source":["from torchvision.models import resnet18\n","resnet18_pretrained = resnet18(pretrained=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"txD0Vn1fn_0W","executionInfo":{"status":"ok","timestamp":1680563711604,"user_tz":-540,"elapsed":637,"user":{"displayName":"권오흠","userId":"05475008821310211864"}},"outputId":"d327cca0-70d8-401f-da0d-50d8b57385ae"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","/usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n","Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n","100%|██████████| 44.7M/44.7M [00:00<00:00, 207MB/s]\n"]}]},{"cell_type":"code","source":["# change the output layer to 10 classes\n","num_classes = 10\n","#num_ftrs를 사전 훈련된 resnet18 모델의 원래 완전 연결 계층의 입력 기능 수로 설정\n","#fc 계층은 num_ftrs 입력기능과 num_classes 출력 기능이 있는 새로운 nn.Linear()계층으로 대체\n","#이 새로운 fc레이어는 이제 cifar-10 데이터 세트의 10개 클래스에 대한 점수를 출력\n","num_ftrs = resnet18_pretrained.fc.in_features\n","resnet18_pretrained.fc = nn.Linear(num_ftrs, num_classes)\n","\n","device = torch.device('cuda:0')\n","resnet18_pretrained.to(device)"],"metadata":{"id":"dnP7it8KqXF7","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1680563721212,"user_tz":-540,"elapsed":5649,"user":{"displayName":"권오흠","userId":"05475008821310211864"}},"outputId":"a44fb4ce-4388-4fe0-d795-e686207ec38e"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["ResNet(\n","  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (relu): ReLU(inplace=True)\n","  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","  (layer1): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (layer2): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (layer3): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (layer4): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n","  (fc): Linear(in_features=512, out_features=10, bias=True)\n",")"]},"metadata":{},"execution_count":4}]},{"cell_type":"code","source":["#사전 훈련된 resnet18 모델의 요약을 인쇄 모델과 데이터 입력 크기라는 두 가지 인수 사용\n","from torchsummary import summary\n","# print(resnet18_pretrained)\n","# 224*224 RGB 이미지 나타냄 요약에는 모델의 레이어, 각 레이어의 출력 모양, 매개변수 수 및 출력 텐서의 크기가 포함된 테이블\n","print(summary(resnet18_pretrained, (3, 224, 224)))"],"metadata":{"id":"Sqg36Qgdpaqq","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1680563787630,"user_tz":-540,"elapsed":7310,"user":{"displayName":"권오흠","userId":"05475008821310211864"}},"outputId":"5ec5f86e-a66b-415a-f804-1c3c14cd303f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1         [-1, 64, 112, 112]           9,408\n","       BatchNorm2d-2         [-1, 64, 112, 112]             128\n","              ReLU-3         [-1, 64, 112, 112]               0\n","         MaxPool2d-4           [-1, 64, 56, 56]               0\n","            Conv2d-5           [-1, 64, 56, 56]          36,864\n","       BatchNorm2d-6           [-1, 64, 56, 56]             128\n","              ReLU-7           [-1, 64, 56, 56]               0\n","            Conv2d-8           [-1, 64, 56, 56]          36,864\n","       BatchNorm2d-9           [-1, 64, 56, 56]             128\n","             ReLU-10           [-1, 64, 56, 56]               0\n","       BasicBlock-11           [-1, 64, 56, 56]               0\n","           Conv2d-12           [-1, 64, 56, 56]          36,864\n","      BatchNorm2d-13           [-1, 64, 56, 56]             128\n","             ReLU-14           [-1, 64, 56, 56]               0\n","           Conv2d-15           [-1, 64, 56, 56]          36,864\n","      BatchNorm2d-16           [-1, 64, 56, 56]             128\n","             ReLU-17           [-1, 64, 56, 56]               0\n","       BasicBlock-18           [-1, 64, 56, 56]               0\n","           Conv2d-19          [-1, 128, 28, 28]          73,728\n","      BatchNorm2d-20          [-1, 128, 28, 28]             256\n","             ReLU-21          [-1, 128, 28, 28]               0\n","           Conv2d-22          [-1, 128, 28, 28]         147,456\n","      BatchNorm2d-23          [-1, 128, 28, 28]             256\n","           Conv2d-24          [-1, 128, 28, 28]           8,192\n","      BatchNorm2d-25          [-1, 128, 28, 28]             256\n","             ReLU-26          [-1, 128, 28, 28]               0\n","       BasicBlock-27          [-1, 128, 28, 28]               0\n","           Conv2d-28          [-1, 128, 28, 28]         147,456\n","      BatchNorm2d-29          [-1, 128, 28, 28]             256\n","             ReLU-30          [-1, 128, 28, 28]               0\n","           Conv2d-31          [-1, 128, 28, 28]         147,456\n","      BatchNorm2d-32          [-1, 128, 28, 28]             256\n","             ReLU-33          [-1, 128, 28, 28]               0\n","       BasicBlock-34          [-1, 128, 28, 28]               0\n","           Conv2d-35          [-1, 256, 14, 14]         294,912\n","      BatchNorm2d-36          [-1, 256, 14, 14]             512\n","             ReLU-37          [-1, 256, 14, 14]               0\n","           Conv2d-38          [-1, 256, 14, 14]         589,824\n","      BatchNorm2d-39          [-1, 256, 14, 14]             512\n","           Conv2d-40          [-1, 256, 14, 14]          32,768\n","      BatchNorm2d-41          [-1, 256, 14, 14]             512\n","             ReLU-42          [-1, 256, 14, 14]               0\n","       BasicBlock-43          [-1, 256, 14, 14]               0\n","           Conv2d-44          [-1, 256, 14, 14]         589,824\n","      BatchNorm2d-45          [-1, 256, 14, 14]             512\n","             ReLU-46          [-1, 256, 14, 14]               0\n","           Conv2d-47          [-1, 256, 14, 14]         589,824\n","      BatchNorm2d-48          [-1, 256, 14, 14]             512\n","             ReLU-49          [-1, 256, 14, 14]               0\n","       BasicBlock-50          [-1, 256, 14, 14]               0\n","           Conv2d-51            [-1, 512, 7, 7]       1,179,648\n","      BatchNorm2d-52            [-1, 512, 7, 7]           1,024\n","             ReLU-53            [-1, 512, 7, 7]               0\n","           Conv2d-54            [-1, 512, 7, 7]       2,359,296\n","      BatchNorm2d-55            [-1, 512, 7, 7]           1,024\n","           Conv2d-56            [-1, 512, 7, 7]         131,072\n","      BatchNorm2d-57            [-1, 512, 7, 7]           1,024\n","             ReLU-58            [-1, 512, 7, 7]               0\n","       BasicBlock-59            [-1, 512, 7, 7]               0\n","           Conv2d-60            [-1, 512, 7, 7]       2,359,296\n","      BatchNorm2d-61            [-1, 512, 7, 7]           1,024\n","             ReLU-62            [-1, 512, 7, 7]               0\n","           Conv2d-63            [-1, 512, 7, 7]       2,359,296\n","      BatchNorm2d-64            [-1, 512, 7, 7]           1,024\n","             ReLU-65            [-1, 512, 7, 7]               0\n","       BasicBlock-66            [-1, 512, 7, 7]               0\n","AdaptiveAvgPool2d-67            [-1, 512, 1, 1]               0\n","           Linear-68                   [-1, 10]           5,130\n","================================================================\n","Total params: 11,181,642\n","Trainable params: 11,181,642\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 0.57\n","Forward/backward pass size (MB): 62.79\n","Params size (MB): 42.65\n","Estimated Total Size (MB): 106.01\n","----------------------------------------------------------------\n","None\n"]}]},{"cell_type":"code","source":["#matplotlib 및 torchvision의 'utils' 모듈 사용하여 사전 훈련된 모델의\n","#첫 번째 컨볼루션 계층의 필터를 시각화\n","from torchvision import utils\n","from matplotlib import pyplot as plt\n","\n","# visualize the filters of the first CNN layer\n","#루프는 resnet18 모델의 매개변수를 반복하며 매개변수의 첫 번째 세트는 첫번째 컨볼루션 레이어의 가중치에 해당\n","for w in resnet18_pretrained.parameters():\n","  #가중치 텐서의 모양이 인쇄, 7*7 크기의 3개의 입력 채널이 있는 64개의 필터 (64,2,7,7)\n","    w = w.data.cpu()\n","    print(w.shape)\n","    break\n","\n","# normalize weights\n","# 가중치 정규화\n","min_w = torch.min(w)\n","w1 = (-1/(2 * min_w)) * w + 0.5\n","\n","# make grid to display it\n","grid_size = len(w1)\n","x_grid = [w1[i] for i in range(grid_size)]\n","# 가중치가 그리드로 변환 여러 이미지를 그리드로 연결\n","x_grid = utils.make_grid(x_grid, nrow=8, padding=1)\n","x_grid = x_grid.numpy()\n","\n","#결과 그리드는 matplotlib를 사용하여 플로팅되어 첫 번째 컨볼루션 레이어에 있는 64개 필터 시각화\n","plt.figure(figsize=(8, 8))\n","plt.imshow(np.transpose(x_grid, (1, 2, 0)))\n","plt.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":732},"id":"DbV8S4qtpkSY","executionInfo":{"status":"ok","timestamp":1680563792291,"user_tz":-540,"elapsed":729,"user":{"displayName":"권오흠","userId":"05475008821310211864"}},"outputId":"185e3059-ea94-46cf-e13c-4df989c1e599"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"]},{"output_type":"stream","name":"stdout","text":["torch.Size([64, 3, 7, 7])\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 800x800 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}]},{"cell_type":"code","source":["#사전 훈련된 resnet18 모델의 정확도를 평가\n","#to 메서드는 모델을 device 변수로 지정된 장치로 이동하는데 사용\n","resnet18_pretrained.to(device)\n","#테스트 세트 반복하고 모델을 각 입력 이미지에 적용\n","#테스트 세트에서 모델을 평가하고 가중치를 업데이트하지 않기를 원하기 때문에 기울기 계싼을 비활성화\n","with torch.no_grad():\n","    correct = 0\n","    total = 0\n","    for images, labels in test_loader:\n","        images = images.to(device)\n","        labels = labels.to(device)\n","        outputs = resnet18_pretrained(images)\n","        #모델의 출력 확률에서 가장 높은 점수를 가진 예측 클래스 레이블 얻는데 사용\n","        _, predicted = torch.max(outputs.data, 1)\n","        total += labels.size(0)\n","        #올바르게 분류된 테스트 이미지의 총 갯수 correct / 전체는 total\n","        correct += (predicted == labels).sum().item()\n","        del images, labels, outputs\n","\n","    print('Accuracy of the network on the {} test images: {} %'.format(10000, 100 * correct / total))   "],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"d0lg5axGqkW5","executionInfo":{"status":"ok","timestamp":1680132423037,"user_tz":-540,"elapsed":26436,"user":{"displayName":"권오흠","userId":"05475008821310211864"}},"outputId":"e857b8ce-aad2-412e-a3a9-e44a6b2299bd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy of the network on the 10000 test images: 9.42 %\n"]}]},{"cell_type":"markdown","source":["우리가 추가한 마지막 레이어는 트레이닝되지 않았음으로 10% 정도의 정답율을 자연스런 것이다. "],"metadata":{"id":"tmw960dusrj2"}}]}