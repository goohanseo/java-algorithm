{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"sYchhei7gc0a"},"outputs":[],"source":["%matplotlib inline"]},{"cell_type":"markdown","metadata":{"id":"RQIPP4Kdgc0f"},"source":["텐서(Tensor)\n","==========================================================================\n","\n","텐서(tensor)는 배열(array)이나 행렬(matrix)과 매우 유사한 특수한 자료구조이다.\n","PyTorch에서는 모델의 **입력(input)**과 **출력(output)**, **중간 계산 결과**, 그리고 모델의 **매개변수**들을 텐서 타입의 객체로 저장한다.\n","\n","텐서는 GPU나 다른 하드웨어 가속기에서 실행할 수 있다는 점만 제외하면 `NumPy`의 `ndarray`와 유사하다. 실제로 텐서와 NumPy 배열(array)은 종종 동일한 내부 메모리를 공유할 수 있어 데이터를 복사할 필요가 없기도 하다.\n","\n","텐서는 또한 자동 미분(automatic differentiation)에 최적화되어 있다. 자동 미분에 대해서는 나중에 따로 다룬다."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-DLQBSNugc0i"},"outputs":[],"source":["import torch\n","import numpy as np"]},{"cell_type":"markdown","metadata":{"id":"rLmjg60Hgc0i"},"source":["## 텐서(tensor)의 생성"]},{"cell_type":"markdown","metadata":{"id":"RrB5I9Fah_-q"},"source":["### 데이터로부터 직접 생성하기"]},{"cell_type":"markdown","metadata":{"id":"HYve9iP-iEyC"},"source":["기본적인 형태의 신경망의 경우에 사용자가 직접 텐서를 생성할 필요는 별로 없다. 입력 텐서는 `DataLoader`에 의해서 자동으로 생성되고, 신경망의 패러매터들은 `torch.nn`이 제공하는 모듈내에 이미 포함되어 있기 때문이다. 다만 신경망의 출력 텐서를 최종적으로 배열이나 스칼라 값으로 변환하는 일은 해주어야 하는 경우가 있다. \n","\n","하지만 조금 복잡한 구조의 신경망을 구성할 경우 때때로 텐서를 직접 생성해주어야 할 수도 있다. 스칼라 데이터나 리스트로부터 직접 텐서를 생성할 수 있다. 이때 데이터의 자료형(data type)은 명시적으로 지정해 줄 수도 있고, 지정하지 않으면 자동으로 유추한다."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tqEE03LGgc0j","outputId":"a03dee90-44f5-44b3-d156-bb828f5e3c5d","executionInfo":{"status":"ok","timestamp":1681978402856,"user_tz":-540,"elapsed":289,"user":{"displayName":"구한서 (hanseo)","userId":"04169580702962661413"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[1, 2],\n","        [3, 4]])"]},"metadata":{},"execution_count":5}],"source":["#길이가 2인 2개의 하위 목록을 포함하는 2D python 목록 data 생성\n","data = [[1, 2],[3, 4]]\n","#torch.tensor 사용하여 pytorch 텐서 x_data로 변환\n","x_data = torch.tensor(data)\n","x_data\n","#결과 텐서는 (2,2)차원 가지며 원래 목록 데이터와 동일한 값을 포함"]},{"cell_type":"markdown","metadata":{"id":"rCNP6Z8XiaZ7"},"source":["### NumPy 배열로부터 생성하기"]},{"cell_type":"markdown","metadata":{"id":"eFi-3oplgc0j"},"source":["텐서는 NumPy 배열로부터 생성할 수 있다. 그 반대도 가능하다.\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rqSEdABvgc0k","outputId":"55fbc9ff-288f-450c-cc77-7d31de881cb6","executionInfo":{"status":"ok","timestamp":1681978406579,"user_tz":-540,"elapsed":675,"user":{"displayName":"구한서 (hanseo)","userId":"04169580702962661413"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[1, 2],\n","        [3, 4]])\n","torch.int64\n","tensor([[1., 2.],\n","        [3., 4.]], dtype=torch.float64)\n","torch.float64\n","tensor([[0, 2],\n","        [3, 4]])\n","tensor([[1., 2.],\n","        [3., 4.]], dtype=torch.float64)\n"]}],"source":["#numpy배열 생성\n","np_array = np.array(data)\n","# from_numpy 메서드로 Tensor를 생성\n","x_np = torch.from_numpy(np_array)\n","print(x_np)\n","#dtype 속성 사용하여 tensor x-np와 데이터 유형 인쇄 \n","print(x_np.dtype)\n","#torch 모듈의 tensor생성자를 사용하여 x_np2라는 또 다른 텐서 생성 인수는 float으로 지정\n","x_np2 = torch.tensor(np_array, dtype=float) # torch.tensor 생성자로 Tensor를 생성할 수도 있음. dtype을 지정 가능\n","\n","print(x_np2)\n","#dtype 속성하용하여 tensor x_np2와 데이터 유형 인쇄\n","print(x_np2.dtype)\n","\n","# 배열의 값을 수정한다.\n","np_array[0, 0] = 0    \n","# from_numpy로 생성한 경우 배열의 데이터를 공유한다.\n","print(x_np)     \n","# tensor 생성자로 생성한 경우 배열의 데이터를 공유하지 않는다.\n","print(x_np2)    "]},{"cell_type":"markdown","metadata":{"id":"6cab27W0jhjE"},"source":["### 모양(shape)을 지정하여 텐서 생성하기"]},{"cell_type":"markdown","metadata":{"id":"PBiJy5bOgc0l"},"source":["``shape`` 은 텐서의 모양을 나타내는 튜플(tuple)로, 아래 함수들에 출력 텐서의 모양을 결정한다."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Z_36o5C9gc0m","outputId":"c3ea156a-8791-452c-ff64-8e63fa81b486","executionInfo":{"status":"ok","timestamp":1681978411252,"user_tz":-540,"elapsed":294,"user":{"displayName":"구한서 (hanseo)","userId":"04169580702962661413"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Random Tensor: \n"," tensor([[0.2870, 0.4751, 0.5503],\n","        [0.2546, 0.8531, 0.5603]])\n","\n","Ones Tensor: \n"," tensor([[1., 1., 1.],\n","        [1., 1., 1.]])\n","\n","Zeros Tensor: \n"," tensor([[0., 0., 0.],\n","        [0., 0., 0.]])\n"]}],"source":["shape = (2,3)\n","# 0~1 사이의 랜덤 실수\n","rand_tensor = torch.rand(shape)   \n","#1로 채워진 텐서  \n","ones_tensor = torch.ones(shape)\n","#0으로 채워진 텐서\n","zeros_tensor = torch.zeros(shape)\n","\n","print(f\"Random Tensor: \\n {rand_tensor}\\n\")\n","print(f\"Ones Tensor: \\n {ones_tensor}\\n\")\n","print(f\"Zeros Tensor: \\n {zeros_tensor}\")"]},{"cell_type":"markdown","metadata":{"id":"5MDt-bWrjTRR"},"source":["### 다른 텐서로부터 생성하기"]},{"cell_type":"markdown","metadata":{"id":"Kbfxdlsggc0k"},"source":["명시적으로 새로 정의하지 않는다면, 인자로 주어진 텐서의 속성(`shape`, `dtype`)을 유지한다."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"crqpLcRugc0l","outputId":"011ecbf2-da81-4026-9d72-8d63641dd03b","executionInfo":{"status":"ok","timestamp":1681978456600,"user_tz":-540,"elapsed":303,"user":{"displayName":"구한서 (hanseo)","userId":"04169580702962661413"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[1, 1],\n","        [1, 1]])\n","tensor([[0, 0],\n","        [0, 0]])\n","tensor([[0.4350, 0.5442],\n","        [0.3019, 0.4912]])\n"]}],"source":["# x_data의 속성을 유지합니다.\n","x_ones = torch.ones_like(x_data)   \n","print(x_ones)\n","\n","# x_data의 속성을 유지합니다.\n","x_zeros = torch.zeros_like(x_data) \n","print(x_zeros)\n","\n","# x_data의 속성을 덮어씁니다.\n","x_rand = torch.rand_like(x_data, dtype=torch.float) \n","print(x_rand)"]},{"cell_type":"markdown","metadata":{"id":"TvV0BBDugc0m"},"source":["--------------"]},{"cell_type":"markdown","metadata":{"id":"CIGZmuiwjvR5"},"source":["## 텐서의 기본 속성(attributes)"]},{"cell_type":"markdown","metadata":{"id":"31W6KynXgc0m"},"source":["모든 텐서는 모양(shape), 자료형(datatype) 및 어느 장치에 저장되는지 등의 속성을 가진다."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8tUZSlNNgc0n","outputId":"572d85ce-d7c2-47f4-a2a9-9e126894c607"},"outputs":[{"output_type":"stream","name":"stdout","text":["Shape of tensor: torch.Size([3, 4])\n","Datatype of tensor: torch.float32\n","Device tensor is stored on: cpu\n"]}],"source":["tensor = torch.rand(3,4)\n","\n","print(f\"Shape of tensor: {tensor.shape}\")\n","print(f\"Datatype of tensor: {tensor.dtype}\")\n","print(f\"Device tensor is stored on: {tensor.device}\")"]},{"cell_type":"markdown","source":["**참고:** 지난 시간의 `PyTorch_Quickstart` 강좌에서 다룬 입력과 출력 데이터들의 타입과 `shape`, `dtype`등의 속성을 확인해보자."],"metadata":{"id":"9Zj8h6gCj5ag"}},{"cell_type":"markdown","metadata":{"id":"b8sepU0Wgc0o"},"source":["--------------"]},{"cell_type":"markdown","metadata":{"id":"7_aDvaB0kFgQ"},"source":["## 텐서 연산(Operation)"]},{"cell_type":"markdown","metadata":{"id":"k2H4zqa-gc0o"},"source":["전치(transposing), 인덱싱(indexing), 슬라이싱(slicing), 수학 계산, 선형 대수 연산,\n","랜덤 샘플링(random sampling) 등 다양한 텐서 연산들을\n","[여기](<https://pytorch.org/docs/stable/torch.html>)에서 확인할 수 있다. 목록에서 몇몇 연산들을 시도해보라.\n","NumPy API에 익숙하다면 Tensor API를 사용하는 것은 쉽다는 것을 알게 될 것이다.\n","\n","각 연산들은 (일반적으로 CPU보다 빠른) GPU에서 실행할 수도 있다. Colab을 사용한다면, `Edit > Notebook Settings` 에서 GPU를 할당할 수 있다.\n","\n","기본적으로 텐서는 CPU에 생성된다. ``.to`` 메소드를 사용하면 GPU로 텐서를 명시적으로 이동할 수 있다. 장치들 간에 큰 텐서들을 복사하는 것은 시간과 메모리 측면에서 비용이 많이든다는 것을 기억하라!"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_k0JzmAjgc0p"},"outputs":[],"source":["# GPU가 존재하면 텐서를 이동합니다\n","if torch.cuda.is_available():\n","    tensor = tensor.to(\"cuda\")"]},{"cell_type":"markdown","metadata":{"id":"GtuM9n5bgc0p"},"source":["#### **NumPy 방식의 인덱싱과 슬라이싱:**\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"C-KYJWDRgc0q","outputId":"a98e9009-2870-4d30-b4b0-540e7c83c48d"},"outputs":[{"output_type":"stream","name":"stdout","text":["First row: tensor([1, 2, 3, 4])\n","First column: tensor([ 1,  5,  9, 13])\n","Last column: tensor([ 4,  8, 12, 16])\n","tensor([[ 1,  0,  3,  4],\n","        [ 5,  0,  7,  8],\n","        [ 9,  0, 11, 12],\n","        [13,  0, 15, 16]])\n"]}],"source":["tensor = torch.tensor([[1,2,3,4],\n","                       [5,6,7,8],\n","                       [9,10,11,12],\n","                       [13,14,15,16]\n","                       ])\n","print(f\"First row: {tensor[0]}\")\n","print(f\"First column: {tensor[:, 0]}\")\n","print(f\"Last column: {tensor[..., -1]}\")    # ...은 앞쪽의 모든 차원에 대해서 \"모든 범위\"임을 의미한다. 3차원 이상의 다차원 배열을 다룰 때 유용한 표현이다.\n","tensor[:,1] = 0\n","print(tensor)"]},{"cell_type":"markdown","metadata":{"id":"Fx4rmDnYgc0q"},"source":["#### **텐서 합치기:** \n","\n","``torch.cat``을 사용하여 주어진 차원에 따라 일련의 텐서를 연결할 수 있다."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-oUYuIU2gc0q","outputId":"3f57d8b4-95b4-4d86-df06-221ed27e93a6"},"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[ 1,  2,  3,  4],\n","        [ 5,  6,  7,  8],\n","        [ 9, 10, 11, 12],\n","        [ 1,  2,  3,  4],\n","        [ 5,  6,  7,  8],\n","        [ 9, 10, 11, 12]])\n","tensor([[ 1,  2,  3,  4,  1,  2,  3,  4],\n","        [ 5,  6,  7,  8,  5,  6,  7,  8],\n","        [ 9, 10, 11, 12,  9, 10, 11, 12]])\n"]}],"source":["tensor = torch.tensor([[1,2,3,4],\n","                       [5,6,7,8],\n","                       [9,10,11,12]])\n","#torch.cat 함수는 행과 열을 따라 텐서를 자신과 연결하는데 사용\n","t0 = torch.cat([tensor, tensor])\n","print(t0)\n","t1 = torch.cat([tensor, tensor], dim=1)  # dim을 지정하여 어떤 축으로 연결할지 지정한다.\n","print(t1)"]},{"cell_type":"markdown","source":["`torch.cat`과는 달리 `torch.stack`은 새로운 차원을 추가하여 텐서를 합친다."],"metadata":{"id":"GMNNGRlWpvYR"}},{"cell_type":"code","source":["t2 = torch.stack([tensor, tensor])\n","print(t2.shape)\n","print(t2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5f0hf2zJp5_q","outputId":"c3ae6b4b-efcf-4a42-deb4-82ab786ebd3a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([2, 3, 4])\n","tensor([[[ 1,  2,  3,  4],\n","         [ 5,  6,  7,  8],\n","         [ 9, 10, 11, 12]],\n","\n","        [[ 1,  2,  3,  4],\n","         [ 5,  6,  7,  8],\n","         [ 9, 10, 11, 12]]])\n"]}]},{"cell_type":"markdown","source":["위의 예에서 보듯 새로 추가된 차원이 첫 번째 축(axis)이 된다. `axis` 인자를 통해서 새로 추가된 차원이 몇 번째 축이 될지 지정할 수도 있다."],"metadata":{"id":"lZf1XzrTqcwg"}},{"cell_type":"code","source":["t3 = torch.stack([tensor, tensor], axis=1)\n","print(t3.shape)\n","print(t3)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PETA1f_BqQ_I","outputId":"eaacdc67-fd44-4ca9-bb5f-a6f2ac61b94d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([3, 2, 4])\n","tensor([[[ 1,  2,  3,  4],\n","         [ 1,  2,  3,  4]],\n","\n","        [[ 5,  6,  7,  8],\n","         [ 5,  6,  7,  8]],\n","\n","        [[ 9, 10, 11, 12],\n","         [ 9, 10, 11, 12]]])\n"]}]},{"cell_type":"markdown","source":["#### **텐서 모양 변경하기(reshape):** "],"metadata":{"id":"MufgjNCpfgAl"}},{"cell_type":"markdown","source":["원소의 개수가 유지되는 경우 텐서의 차원의 개수와 모양을 자유롭게 변경할 수 있다."],"metadata":{"id":"3evwW8DNg4ut"}},{"cell_type":"code","source":["a = torch.arange(12)\n","a"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hSAMuO9lf5Ux","outputId":"4d2304c8-3f3f-4f22-ce9e-258a62dfaa5f"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11])"]},"metadata":{},"execution_count":21}]},{"cell_type":"code","source":["a = torch.reshape(a, (1, 3, 4))\n","a"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uXdhtUcagGhm","outputId":"e2ee2717-f019-4aa0-f667-08c86733719d"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[[ 0,  1,  2,  3],\n","         [ 4,  5,  6,  7],\n","         [ 8,  9, 10, 11]]])"]},"metadata":{},"execution_count":22}]},{"cell_type":"markdown","source":["원소의 개수는 불변이므로 크기가 유추 가능한 경우 -1로 표시할 수 있다."],"metadata":{"id":"Yzb5IBB0hD5z"}},{"cell_type":"code","source":["b = torch.reshape(a, (-1, 2, 3))\n","print(b)\n","print(b.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jDxucu4cgXuK","outputId":"19dc4488-f427-45d3-ed1d-b86144055e09"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[[ 0,  1,  2],\n","         [ 3,  4,  5]],\n","\n","        [[ 6,  7,  8],\n","         [ 9, 10, 11]]])\n","torch.Size([2, 2, 3])\n"]}]},{"cell_type":"markdown","source":["`squeeze` 메서드로 크기가 1인 차원을 제거하거나, `unsqueez` 메서드로 차원을 추가할 수 있다."],"metadata":{"id":"VKYvl43ZhLNL"}},{"cell_type":"code","source":["x = torch.rand(1, 1, 20, 128)\n","x = x.squeeze() # [1, 1, 20, 128] -> [20, 128]\n","print(x.shape)\n","\n","x2 = torch.rand(1, 1, 20, 128)\n","x2 = x2.squeeze(dim=1) # [1, 1, 20, 128] -> [1, 20, 128]\n","print(x2.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5lVPNqTahigL","outputId":"00624026-530a-4772-e854-f4eac6e4d101"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([20, 128])\n","torch.Size([1, 20, 128])\n"]}]},{"cell_type":"code","source":["x = torch.rand([2, 3])\n","x1 = torch.unsqueeze(x, 0)\n","x1.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"f1PVnLNOhrjk","outputId":"47860f92-7aee-4a10-b351-97ba0bde6512"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([1, 2, 3])"]},"metadata":{},"execution_count":24}]},{"cell_type":"markdown","source":["이외에도 텐서의 모양을 변경하는 방법으로는 [`flatten`](https://pytorch.org/docs/stable/generated/torch.flatten.html), [`view`](https://pytorch.org/docs/stable/generated/torch.Tensor.view.html), [`expand`](https://pytorch.org/docs/stable/generated/torch.Tensor.expand.html), `None` indexing 등이 있다."],"metadata":{"id":"6D8htJ79N0Va"}},{"cell_type":"markdown","metadata":{"id":"SQISmlnmgc0r"},"source":["#### **산술 연산(Arithmetic operations)**\n","\n"]},{"cell_type":"markdown","source":[" 텐서와 스칼라간의 기본적인 산술 연산을 지원한다."],"metadata":{"id":"3bmLk1qkQxwY"}},{"cell_type":"code","source":["ones = torch.zeros(2, 2) + 1\n","twos = torch.ones(2, 2) * 2\n","threes = (torch.ones(2, 2) * 7 - 1) / 2\n","fours = twos ** 2\n","sqrt2s = twos ** 0.5\n","\n","print(ones)\n","print(twos)\n","print(threes)\n","print(fours)\n","print(sqrt2s)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8R9l9DXCQ0mg","outputId":"1b79e894-1eb1-45ea-df3c-2771e278d59f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[1., 1.],\n","        [1., 1.]])\n","tensor([[2., 2.],\n","        [2., 2.]])\n","tensor([[3., 3.],\n","        [3., 3.]])\n","tensor([[4., 4.],\n","        [4., 4.]])\n","tensor([[1.4142, 1.4142],\n","        [1.4142, 1.4142]])\n"]}]},{"cell_type":"code","source":["fives = ones + fours\n","print(fives)\n","\n","# 요소별 곱(element-wise product)을 계산한다. dozens1, dozens2는 같은 값을 갖는다.\n","dozens1 = threes * fours\n","dozens2 = threes.mul(fours)\n","print(dozens1)\n","print(dozens2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"m3_RyZiRRZI5","outputId":"0f4404a7-b89f-4a60-fb91-bc3b2acdc52a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[5., 5.],\n","        [5., 5.]])\n","tensor([[12., 12.],\n","        [12., 12.]])\n","tensor([[12., 12.],\n","        [12., 12.]])\n"]}]},{"cell_type":"markdown","source":["행렬곱은 `@` 연산자 혹은 `matmul` 메서드로 지원한다."],"metadata":{"id":"PJMnJraHR_e7"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nNO4DK7sgc0r","outputId":"d2880da4-0dfe-435e-ba8f-af57ede65dd5"},"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[ 30,  70, 110],\n","        [ 70, 174, 278],\n","        [110, 278, 446]])\n","tensor([[  1,   4,   9,  16],\n","        [ 25,  36,  49,  64],\n","        [ 81, 100, 121, 144]])\n"]}],"source":["# 두 텐서 간의 행렬 곱(matrix multiplication)을 계산한니다. y1, y2는 같은 값을 갖는다.\n","y1 = tensor @ tensor.T\n","y2 = tensor.matmul(tensor.T)\n","print(y1)"]},{"cell_type":"markdown","source":["#### Broadcasting"],"metadata":{"id":"FBskkgGyS2UI"}},{"cell_type":"markdown","source":["Broadcasting은 서로 다른 shape을 가진 텐서끼리 산술연산을 지원하는 기법을 의미한다. 예를 들어보자."],"metadata":{"id":"dygHIRm2TGQ2"}},{"cell_type":"code","source":["A = torch.rand(2, 4)  \n","B = torch.ones(1, 4) * 2\n","print(A)\n","print(B)\n","C = A + B\n","print(C)\n","D = A * B\n","print(D)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2Y5FD3C0TSpD","outputId":"4153ceaa-b3ac-464c-f19c-ddee78bc55a8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[0.4544, 0.5118, 0.6063, 0.4226],\n","        [0.8554, 0.9073, 0.6393, 0.5394]])\n","tensor([[2., 2., 2., 2.]])\n","tensor([[2.4544, 2.5118, 2.6063, 2.4226],\n","        [2.8554, 2.9073, 2.6393, 2.5394]])\n","tensor([[0.9088, 1.0236, 1.2126, 0.8451],\n","        [1.7108, 1.8147, 1.2786, 1.0788]])\n"]}]},{"cell_type":"markdown","source":[" Broadcasting에 관한 세부규칙은 Numpy와 동일하다."],"metadata":{"id":"nvK04MjgVfcU"}},{"cell_type":"markdown","source":["#### 기타 산술연산"],"metadata":{"id":"lXMXtYR0S7X3"}},{"cell_type":"markdown","source":["텐서는 이외에도 매우 다양한 산술연산을 제공한다."],"metadata":{"id":"DGEIqXgASjTk"}},{"cell_type":"code","source":["# common functions\n","a = torch.rand(2, 4) * 2 - 1\n","print(a)\n","print('Common functions:')\n","print(torch.abs(a))\n","print(torch.ceil(a))  # 올림 연산\n","print(torch.floor(a)) # 내림 연산\n","print(torch.clamp(a, -0.5, 0.5)) # -0.5 이하는 -0.5로, 0.5 이상은 0.5로 변환\n","\n","# comparisons:\n","print('\\nBroadcasted, element-wise equality comparison:')\n","d = torch.tensor([[1., 2.], [3., 4.]])\n","e = torch.ones(1, 2)  # many comparison ops support broadcasting!\n","print(torch.eq(d, e)) # returns a tensor of type bool\n","\n","# reductions:\n","print('\\nReduction ops:')\n","print(torch.max(d))        # returns a single-element tensor\n","print(torch.min(d))        # returns a single-element tensor\n","print(torch.mean(d))       # average\n","print(torch.std(d))        # standard deviation\n","print(torch.prod(d))       # product of all numbers"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EnU5StdTSpLD","outputId":"63009d8e-697e-47d3-83e5-26c9335afff0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[ 0.9577, -0.3478,  0.8367, -0.7660],\n","        [-0.2441, -0.2934,  0.6736,  0.3762]])\n","Common functions:\n","tensor([[0.9577, 0.3478, 0.8367, 0.7660],\n","        [0.2441, 0.2934, 0.6736, 0.3762]])\n","tensor([[1., -0., 1., -0.],\n","        [-0., -0., 1., 1.]])\n","tensor([[ 0., -1.,  0., -1.],\n","        [-1., -1.,  0.,  0.]])\n","tensor([[ 0.5000, -0.3478,  0.5000, -0.5000],\n","        [-0.2441, -0.2934,  0.5000,  0.3762]])\n","\n","Broadcasted, element-wise equality comparison:\n","tensor([[ True, False],\n","        [False, False]])\n","\n","Reduction ops:\n","tensor(4.)\n","tensor(1.)\n","tensor(2.5000)\n","tensor(1.2910)\n","tensor(24.)\n"]}]},{"cell_type":"markdown","metadata":{"id":"PZcfgJBGgc0s"},"source":["#### **단일-요소(single-element) 텐서:** \n","\n","단일 스칼라 값을 저장하는 텐서의 경우, ``item()``을 사용하여 숫자 값으로 변환할 수 있다:\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"V7ZovXBWgc0s","outputId":"19fb4a15-bc14-4688-fe08-8093cc425ccf"},"outputs":[{"output_type":"stream","name":"stdout","text":["78 <class 'int'>\n"]}],"source":["agg = tensor.sum()   # 1 + 2 + ... + 12 = 78\n","agg_item = agg.item()\n","print(agg_item, type(agg_item))"]},{"cell_type":"markdown","metadata":{"id":"gr2_riHMgc0s"},"source":["#### **바꿔치기(in-place) 연산:**\n","\n","연산 결과를 피연산자(operand)에 저장하는 연산을 바꿔치기 연산이라고 부르며, ``_`` 접미사를 갖는다.\n","예를 들어: ``x.copy_(y)`` 나 ``x.t_()`` 는 ``x`` 를 변경한다.\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9BfWEwPEgc0s"},"outputs":[],"source":["print(f\"{tensor} \\n\")\n","tensor.add_(5)\n","print(tensor)"]},{"cell_type":"markdown","metadata":{"id":"tVEnKMGhgc0t"},"source":["**Note:** 바꿔치기 연산은 메모리를 일부 절약하지만, 기록(history)이 즉시 삭제되어 도함수(derivative) 계산에 문제가 발생할 수 있다. 따라서, 사용을 권장하지 않는다.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"Sr0HMCnhgc0t"},"source":["--------------\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"p1FQ9oB7lJ1f"},"source":["## NumPy 변환(Bridge)"]},{"cell_type":"markdown","metadata":{"id":"8T0LSXIbgc0t"},"source":["CPU 상의 텐서와 NumPy 배열은 메모리 공간을 공유하기 때문에, 하나를 변경하면 다른 하나도 변경된다.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"rkukqnaugc0t"},"source":["#### **텐서를 NumPy 배열로 변환하기**\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UFmYuEUHgc0u","outputId":"e8f19f08-0c71-42a7-8cfe-cd0b6887c49b"},"outputs":[{"name":"stdout","output_type":"stream","text":["t: tensor([1., 1., 1., 1., 1.])\n","n: [1. 1. 1. 1. 1.]\n"]}],"source":["t = torch.ones(5)\n","print(f\"t: {t}\")\n","n = t.numpy()\n","print(f\"n: {n}\")"]},{"cell_type":"markdown","metadata":{"id":"VR626P2Agc0v"},"source":["텐서의 변경 사항이 NumPy 배열에 반영된다.\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"h7FNuKMSgc0v","outputId":"6877caa4-5039-43ab-cec4-d50db3870b07"},"outputs":[{"name":"stdout","output_type":"stream","text":["t: tensor([2., 2., 2., 2., 2.])\n","n: [2. 2. 2. 2. 2.]\n"]}],"source":["t.add_(1)\n","print(f\"t: {t}\")\n","print(f\"n: {n}\")"]},{"cell_type":"markdown","metadata":{"id":"fp7jufosgc0w"},"source":["#### **NumPy 배열을 텐서로 변환하기**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Qg4XrxXMgc0w"},"outputs":[],"source":["n = np.ones(5)\n","t = torch.from_numpy(n)"]},{"cell_type":"markdown","metadata":{"id":"H6LbUsa2gc0x"},"source":["NumPy 배열의 변경 사항이 텐서에 반영된다.\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qtmTH-vsgc0x","outputId":"b563b906-2389-46e1-dda7-a86fc7ca979c"},"outputs":[{"name":"stdout","output_type":"stream","text":["t: tensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n","n: [2. 2. 2. 2. 2.]\n"]}],"source":["np.add(n, 1, out=n)\n","print(f\"t: {t}\")\n","print(f\"n: {n}\")"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.13"}},"nbformat":4,"nbformat_minor":0}