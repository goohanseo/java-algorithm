{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"KtvLywPixvUW","executionInfo":{"status":"ok","timestamp":1682236409983,"user_tz":-540,"elapsed":4,"user":{"displayName":"구한서 (hanseo)","userId":"04169580702962661413"}}},"outputs":[],"source":["%matplotlib inline"]},{"cell_type":"markdown","metadata":{"id":"1re9-2vvxvUZ"},"source":["# 신경망 모델 구성하기\n","\n","신경망은 데이터에 대한 연산을 수행하는 계층(layer)/모듈(module)로 구성되어 있다.\n","[`torch.nn`](<https://pytorch.org/docs/stable/nn.html>) 네임스페이스는 신경망을 구성하는데 필요한 모든 구성 요소를 제공한다.\n","PyTorch의 모든 모듈은 [`nn.Module`](<https://pytorch.org/docs/stable/generated/torch.nn.Module.html>)의 하위 클래스(subclass)\n","이다. 신경망은 그 자체로 다른 모듈 혹은 계층(layer)들로 구성된 하나의 모듈이다. 이러한 중첩된 구조는 복잡한 아키텍처를 쉽게 구축하고 관리할 수 있게 한다.\n","\n","이제 FashionMNIST 데이터셋의 이미지들을 분류하는 신경망을 구성해보자.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NA5QZhvCxvUb"},"outputs":[],"source":["import os\n","import torch\n","from torch import nn\n","from torch.utils.data import DataLoader\n","from torchvision import datasets, transforms"]},{"cell_type":"markdown","metadata":{"id":"XtgxApsSxvUc"},"source":["학습을 위한 장치 얻기\n","------------------------------------------------------------------------------------------\n","\n","가능하다면 GPU와 같은 하드웨어 가속기에서 모델을 학습하는 것이 효율적이다.\n","[`torch.cuda`](<https://pytorch.org/docs/stable/notes/cuda.html>)를 사용할 수 있는지\n","확인하고 그렇지 않으면 CPU를 계속 사용한다."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RuGYC16_xvUc","outputId":"55bcb6d8-94f0-43ba-a8a1-bec7d165381e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Using cuda device\n"]}],"source":["device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","print(f\"Using {device} device\")"]},{"cell_type":"markdown","metadata":{"id":"iz00Sqj2xvUd"},"source":["클래스 정의하기\n","------------------------------------------------------------------------------------------\n","\n","신경망 모델을 ``nn.Module``의 하위클래스로 정의하고, ``__init__``에서 신경망 계층들을 초기화한다.\n","``nn.Module``을 상속받은 모든 클래스는 ``forward`` 메소드에 입력 데이터에 대한 연산들을 구현한다.\n","\n"]},{"cell_type":"code","source":["img_height = 28     # 이미지의 높이\n","img_width = 28      # 이미지의 너비\n","num_channels = 1    # 흑백 이미지이므로 1\n","num_classes = 10    # 분류할 이미지의 클래스는 10가지"],"metadata":{"id":"1Isk16fdL-sm"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tLPYeBVHxvUd"},"outputs":[],"source":["class NeuralNetwork(nn.Module):\n","    #네트워크의 계층을 정의 먼저 입력 텐서를 1D 텐서로 평면화하는 nn.flatten인스턴스 생성\n","    def __init__(self):\n","        super(NeuralNetwork, self).__init__()\n","        self.flatten = nn.Flatten()\n","        #그 다음 선형 및 활성화 계층을 보관하기 위해 nn.sequential 컨테이너 생성\n","        #컨테이너는 세 개의 선형레이어 정의\n","        self.linear_relu_stack = nn.Sequential(\n","            #(img_heightimg_widthnum_channels, 512) 형태의 입력 텐서를 취하고 선형 변환을 적용하여 512 형태의 출력 텐서 생성\n","            nn.Linear(img_height*img_width*num_channels, 512),\n","            #relu 활성화 함수를 첫번째 계층의 출력에 적용\n","            nn.ReLU(),\n","            #512 형태의 입력 텐서를 취하고 선형 변환을 적용하여 num_classes 형태의 출력 텐서를 생성\n","            nn.Linear(512, 512),\n","            nn.ReLU(),\n","            nn.Linear(512, num_classes),\n","        )\n","    #입력 텐서 x가 flatten 계층을 사용하여 평면화되고 linear _relu_stack에 정의된 선형 및 활성화 계층을 통과\n","    def forward(self, x):\n","        x = self.flatten(x)\n","        logits = self.linear_relu_stack(x)\n","        #결과 텐서는 각 입력 샘플에 대해 예측된 클래스 점수를 나타내는 logits로 변환\n","        return logits"]},{"cell_type":"markdown","source":["거의 유사한 구조의 네트워크를 약간 다르게 정의해보았다."],"metadata":{"id":"GlO37KMNLr5n"}},{"cell_type":"code","source":["#3개의 완전히 연결된(선형)계층이 있으며 이들 사이에 ReLU활성화 기능을 사용 \n","#ReLU 단순성, 계산 효율성 및 기울기 소실 문제를 방지하는 기능 rectified linear unit\n","class NeuralNetwork2(nn.Module):\n","    #생성자 init에서 nn.Linear 및 nn.ReLU모듈사용하여 레이어를 설정하고 클래스의 인스턴수 변수로 저장하여 모델을 정의\n","    def __init__(self):\n","        super(NeuralNetwork2, self).__init__()\n","        #fc1 첫번째 완전 연결 계층은 입력 특성이 이미지의 높이, 너비 및 채널 수의 곱, 출력 특성 1024개\n","        self.fc1 = nn.Linear(img_height*img_width*num_channels, 1024) \n","        #fc2 두번째 완전 연결 계층 1024개의 입력 특성과 512개의 출력 특성\n","        self.fc2 = nn.Linear(1024, 512)\n","        #512개의 입력특성과 분류를 위한 클래스 수와 같은 출력 특성\n","        self.fc3 = nn.Linear(512, num_classes)\n","        self.relu = nn.ReLU()\n","    #forward 방법에서는 입력을 view를 사용하여 평면화하여 2D 이미지 텐서에서 1D텐서로 변환\n","    #평평한 텐서는 그 사이에 ReLU 활성화가 있는 3개의 선형 레이어를 통과하고 최종 출력이 반환\n","    #신경망의 순전파 정의\n","    def forward(self, x):\n","      #1D텐서로 변환\n","        x = x.view(x.size(0), -1)     # flatten the input image\n","        #평평한 텐서는 fc1을 통고한 다음 relu 활성화 함수를 거침\n","        out = self.relu(self.fc1(x))\n","        #이전 단계의 출력이 두번째 fc2 거친 다음 다시 relu 활성화 거침\n","        out = self.relu(self.fc2(out))\n","        #fc3거쳐 최종 출력 생성\n","        out = self.fc3(out)\n","        return out"],"metadata":{"id":"5WJ21ewfLzeE"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rJeC_YlFxvUe"},"source":["``NeuralNetwork``의 인스턴스(instance)를 생성하고 이를 ``device``로 이동한 뒤,\n","구조(structure)를 출력한다.\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0QOunk85xvUf","outputId":"50805d38-b66f-4e3d-80a8-3711522e66e6"},"outputs":[{"output_type":"stream","name":"stdout","text":["NeuralNetwork(\n","  (flatten): Flatten(start_dim=1, end_dim=-1)\n","  (linear_relu_stack): Sequential(\n","    (0): Linear(in_features=784, out_features=512, bias=True)\n","    (1): ReLU()\n","    (2): Linear(in_features=512, out_features=512, bias=True)\n","    (3): ReLU()\n","    (4): Linear(in_features=512, out_features=10, bias=True)\n","  )\n",")\n"]}],"source":["model = NeuralNetwork().to(device)\n","print(model)\n","#첫번째 평평한 이미지 텐서 입력 사용하고 512 차원의 텐서를 출력\n","#두번째 이 텐서를 가져와 다시 512 차원의 텐서 출력\n","#3번째 이 텐서를 가져와 num_classes 차원의 텐서를 (출력 모델이 예측해야하는 클래스의 수)"]},{"cell_type":"markdown","metadata":{"id":"h5NYBMzwxvUg"},"source":["모델에 입력 데이터를 전달하면 모델의 ``forward`` 메서드가 자동으로 실행된다. ``model.forward()``를 사용자가 직접 호출하지는 않는다.\n","\n","입력 데이터에 대해 모델을 실행하면 각 분류(class)에 대한 원시(raw) 예측값이 저장된 10-차원 텐서가 반환된다. 이 값을 각 분류에 속할 확률(각각은 0에서 1사이의 실수이고 합이 1이 되는 실수들)로 변환하고 싶다면 ``nn.Softmax`` 모듈을 적용하면 된다. "]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XAnnLarGxvUh","outputId":"3a617e45-c200-4ccb-b560-5a4fa805f038"},"outputs":[{"output_type":"stream","name":"stdout","text":["logits: tensor([[ 0.0698, -0.0292, -0.0986,  0.0445,  0.0170,  0.0153,  0.0006, -0.0215,\n","          0.0360, -0.0048],\n","        [ 0.0596, -0.0491, -0.0849,  0.0363,  0.0162, -0.0029, -0.0198, -0.0381,\n","          0.1013,  0.0874]], device='cuda:0', grad_fn=<AddmmBackward0>)\n","pred_probab: tensor([[0.1068, 0.0967, 0.0903, 0.1041, 0.1013, 0.1012, 0.0997, 0.0975, 0.1033,\n","         0.0991],\n","        [0.1048, 0.0941, 0.0907, 0.1024, 0.1004, 0.0985, 0.0968, 0.0951, 0.1093,\n","         0.1078]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n","Predicted class: tensor([0, 8], device='cuda:0')\n"]}],"source":["#2개의 그레이스케일 이미지를 나타내는 모양 (2,1,28,28)의 임의 텐서 x를 생성\n","#그 다음 모델의 원시 출력인 로직을 얻기 위해 신경망 모델인 모델을 통해 x전달 로직의 모양은 (2,classes)\n","#(이미지수,색상채널수,이미지 높이,너비)\n","X = torch.rand(2, 1, 28, 28, device=device)  # 2 random grayscale images\n","#입력데이터x에 대한 모델의 예측 출력값\n","logits = model(X)\n","print('logits: {}'.format(logits))\n","#소프트맥스 함수 nn.Softmax(dim=1)를 사용하여 로직 텐서의 두번째 차원을 따라 적용되어 (2,num_classes)의 예측 확률 텐서를 얻음\n","#더 정교화된 얘측값 제공\n","pred_probab = nn.Softmax(dim=1)(logits)\n","print('pred_probab: {}'.format(pred_probab))\n","#예측 확률이 가장 높은 클래스를 기반로 2개의 이미지 각각에 대한 예측 클래스 인덱스 얻어 y_pred에 저장\n","y_pred = pred_probab.argmax(1)\n","print(f\"Predicted class: {y_pred}\")"]},{"cell_type":"markdown","metadata":{"id":"L0RSMATSxvUh"},"source":["------------------------------------------------------------------------------------------\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"pJcCD9jexvUi"},"source":["모델 계층(Layer)\n","------------------------------------------------------------------------------------------\n","\n","FashionMNIST 모델의 계층들을 살펴보자. 이를 설명하기 위해, 28x28 크기의 랜덤 이미지 3개로 구성된\n","미니배치를 가져와, 신경망을 통과할 때 어떤 일이 발생하는지 알아본다.\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wUhuRevXxvUi","outputId":"d69e7edb-ddbb-4daa-ff7b-2d6d88a09afa"},"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[[[0.5899, 0.1377, 0.5635,  ..., 0.7419, 0.5389, 0.1329],\n","          [0.4346, 0.5824, 0.1957,  ..., 0.9177, 0.9711, 0.8584],\n","          [0.5505, 0.7385, 0.4338,  ..., 0.3232, 0.7114, 0.1898],\n","          ...,\n","          [0.2887, 0.1678, 0.9462,  ..., 0.7314, 0.4096, 0.9896],\n","          [0.6946, 0.0042, 0.1949,  ..., 0.6815, 0.3720, 0.6154],\n","          [0.2296, 0.9481, 0.8549,  ..., 0.7209, 0.1182, 0.0214]]],\n","\n","\n","        [[[0.2177, 0.5515, 0.6387,  ..., 0.9155, 0.4830, 0.5330],\n","          [0.8900, 0.0887, 0.8392,  ..., 0.7162, 0.9012, 0.3201],\n","          [0.7249, 0.7423, 0.7093,  ..., 0.1522, 0.4259, 0.6443],\n","          ...,\n","          [0.5613, 0.9525, 0.0628,  ..., 0.7070, 0.5746, 0.8042],\n","          [0.9412, 0.5226, 0.9981,  ..., 0.3875, 0.2468, 0.2501],\n","          [0.4412, 0.7136, 0.2252,  ..., 0.2590, 0.7530, 0.8188]]],\n","\n","\n","        [[[0.0178, 0.8296, 0.6243,  ..., 0.2192, 0.6648, 0.8247],\n","          [0.3952, 0.3111, 0.8062,  ..., 0.1829, 0.2982, 0.5585],\n","          [0.1321, 0.4822, 0.0016,  ..., 0.6051, 0.8033, 0.2586],\n","          ...,\n","          [0.2468, 0.8202, 0.8763,  ..., 0.1738, 0.9886, 0.8835],\n","          [0.3935, 0.3775, 0.2903,  ..., 0.5094, 0.1306, 0.9784],\n","          [0.8175, 0.1959, 0.8003,  ..., 0.1495, 0.2644, 0.4105]]]])\n","torch.Size([3, 1, 28, 28])\n"]}],"source":["input_images = torch.rand(3, 1, 28, 28) # 3 random grayscale images\n","#배치에 3개의 이미지 샘플이 있고 각각 1개의 채널이 있고 각 이미지의 높이와 너비가 28픽셀\n","#두번째는 색상 채널인데 회색조이므로 하나만 있으면 된다\n","print(input_images)\n","print(input_images.size())"]},{"cell_type":"markdown","metadata":{"id":"22v6vyICxvUi"},"source":["#### `nn.Flatten`\n","\n","[`nn.Flatten`](<https://pytorch.org/docs/stable/generated/torch.nn.Flatten.html>) 계층은\n","각 28x28의 2D 이미지를 784 픽셀 값을 갖는 1차원 배열로 변환한다. dim=0의 미니배치 차원은 유지된다.\n","\n"]},{"cell_type":"markdown","source":["배치(batch) 처리를 하는 이유는 여러 가지가 있습니다. 가장 큰 이유는 GPU의 병렬 처리 기능을 활용하여 추론 속도를 높이기 위함입니다. GPU는 단일 연산에 대해 매우 높은 성능을 보이는데, 이를 이용하여 한 번에 여러 개의 이미지를 처리하면 전체 추론 시간을 대폭 줄일 수 있습니다.\n","\n","또한, 배치 처리를 함으로써 효율적인 데이터 로딩이 가능해집니다. 이미지 파일을 읽어들이는 작업은 I/O 연산으로 인해 매우 느리기 때문에, 한 번에 여러 개의 이미지를 로딩하여 메모리에 올려두면 I/O 연산을 줄일 수 있습니다.\n","\n","마지막으로, 배치 처리를 함으로써 모델의 일반화 성능을 높일 수 있습니다. 이는 데이터셋에서 임의로 추출된 배치가 전체 데이터셋을 대표하는 정보를 담고 있을 가능성이 높기 때문입니다. 따라서 배치를 이용하여 모델을 학습하면, 전체 데이터셋에 대한 일반화 성능이 향상됩니다.\n","\n","따라서, 배치 처리는 딥러닝 모델의 추론 및 학습에서 중요한 역할을 합니다."],"metadata":{"id":"p0MgXo_kM-EV"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nTOKML8WxvUi","outputId":"5b7cc083-47de-4a9b-b933-c97fcc60edc8"},"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([3, 784])\n"]}],"source":["#크기가 (3,1,28,28)인 텐서 input_images에 nn.Flatten() 작업을 적용하여 각각 임지를 나타냄\n","#nn.Flatten()작업은 각 이미지의 모든 픽셀 값을 연결하여 input_impages의 각 이미지를 1차원 텐서로 병합한다.\n","#결과 flat_image 텐서의 차원은 (3,784)이다. 여기서 3은 배치크기(이미지수)이고 784는 평면화 후 각 이미지의 총 픽셀 수\n","flatten = nn.Flatten()\n","flat_image = flatten(input_images)\n","print(flat_image.size())"]},{"cell_type":"markdown","metadata":{"id":"OvDo6_A0xvUj"},"source":["#### `nn.Linear`\n","\n","[선형 계층](<https://pytorch.org/docs/stable/generated/torch.nn.Linear.html>)은 저장된 가중치(weight)와\n","편향(bias)을 사용하여 입력에 선형 변환(linear transformation)을 적용하는 모듈이다."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lpudx80BxvUj","outputId":"29bd3078-65e4-4c36-cfcf-f8ade2d2dec7"},"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([3, 20])\n","tensor([[-0.5696, -0.0971,  0.4020,  0.1580,  0.5307,  0.1039, -0.5530, -0.2462,\n","          0.0940, -0.5691,  0.0738, -0.1913, -0.0880,  0.2391, -0.1928, -0.3406,\n","          0.7934,  0.2581, -0.1567, -0.0165],\n","        [-0.2834,  0.2402,  0.3911,  0.0409, -0.0400,  0.2782, -0.4495, -0.3883,\n","         -0.1695,  0.1305,  0.1453, -0.1059, -0.4036,  0.1702, -0.1996, -0.1264,\n","          0.4059,  0.2540, -0.2857, -0.0910],\n","        [-0.3287,  0.0295,  0.2424, -0.0582,  0.0675, -0.1619, -0.6016, -0.2853,\n","         -0.1620, -0.4376, -0.2458,  0.3466, -0.2085,  0.1128, -0.1083,  0.1271,\n","          0.2557,  0.0282, -0.0290, -0.3726]], grad_fn=<AddmmBackward0>)\n"]}],"source":["#선형 레이어 layer1정의 후 이 레이어를 평면화된 입력 이미지 flat_image에 \n","#적용 크기가 20인 특징 벡터로 표현하려면 평면화\n","#그 결과 크기가 3*20인 텐서가 생성 \n","layer1 = nn.Linear(in_features=28*28, out_features=20)\n","hidden1 = layer1(flat_image)\n","print(hidden1.size())\n","#배치의 각 이미지에 대한 20개의 숨겨진 단위 값을 포함하는 결과 텐서 출력\n","#20개의 특징을 구함\n","#cnn을 통해 모델 내부에서 자동으로 학습\n","print(hidden1)"]},{"cell_type":"markdown","metadata":{"id":"cLbZWupgxvUj"},"source":["#### `nn.ReLU`\n","\n","비선형 활성화(activation)는 모델의 입력과 출력 사이에 비선형적인 복잡한 관계(mapping)를 만든다.\n","비선형 활성화는 선형 변환 후에 적용되어 *비선형성(nonlinearity)* 을 도입하고, 신경망이 다양한 현상을 학습할 수 있도록 돕는다.\n","\n","이 모델에서는 [`nn.ReLU`](<https://pytorch.org/docs/stable/generated/torch.nn.ReLU.html>)를 사용하지만, 다양한 다른 활성화 함수를 사용할 수도 있다. \n","\n","**Note:** $ReLu(x) = \\max(0, x)$이다.\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mopVyRYDxvUk","outputId":"a1e18a51-2b5f-496d-d153-11ac5ee9a467"},"outputs":[{"output_type":"stream","name":"stdout","text":["Before ReLU: tensor([[-0.5696, -0.0971,  0.4020,  0.1580,  0.5307,  0.1039, -0.5530, -0.2462,\n","          0.0940, -0.5691,  0.0738, -0.1913, -0.0880,  0.2391, -0.1928, -0.3406,\n","          0.7934,  0.2581, -0.1567, -0.0165],\n","        [-0.2834,  0.2402,  0.3911,  0.0409, -0.0400,  0.2782, -0.4495, -0.3883,\n","         -0.1695,  0.1305,  0.1453, -0.1059, -0.4036,  0.1702, -0.1996, -0.1264,\n","          0.4059,  0.2540, -0.2857, -0.0910],\n","        [-0.3287,  0.0295,  0.2424, -0.0582,  0.0675, -0.1619, -0.6016, -0.2853,\n","         -0.1620, -0.4376, -0.2458,  0.3466, -0.2085,  0.1128, -0.1083,  0.1271,\n","          0.2557,  0.0282, -0.0290, -0.3726]], grad_fn=<AddmmBackward0>)\n","\n","\n","After ReLU: tensor([[0.0000, 0.0000, 0.4020, 0.1580, 0.5307, 0.1039, 0.0000, 0.0000, 0.0940,\n","         0.0000, 0.0738, 0.0000, 0.0000, 0.2391, 0.0000, 0.0000, 0.7934, 0.2581,\n","         0.0000, 0.0000],\n","        [0.0000, 0.2402, 0.3911, 0.0409, 0.0000, 0.2782, 0.0000, 0.0000, 0.0000,\n","         0.1305, 0.1453, 0.0000, 0.0000, 0.1702, 0.0000, 0.0000, 0.4059, 0.2540,\n","         0.0000, 0.0000],\n","        [0.0000, 0.0295, 0.2424, 0.0000, 0.0675, 0.0000, 0.0000, 0.0000, 0.0000,\n","         0.0000, 0.0000, 0.3466, 0.0000, 0.1128, 0.0000, 0.1271, 0.2557, 0.0282,\n","         0.0000, 0.0000]], grad_fn=<ReluBackward0>)\n"]}],"source":["#relu 활성화 함수를 layer1의 출력에 적용하여 신경망에 비선형성을 도입\n","#relue 함수는 0과 입력  텐서 사이의 요소별 최대값을 반환\n","print(f\"Before ReLU: {hidden1}\\n\\n\")\n","hidden1 = nn.ReLU()(hidden1)\n","print(f\"After ReLU: {hidden1}\") \n","#relue활성화 함수는 음수 값을 0으로 설정, 양수값은 유지\n","#이렇게 하면 활성화 함수의 출력이 항상 음수가 아니게 되고 신경망에 비선형성이 도입됨"]},{"cell_type":"markdown","metadata":{"id":"hHQzZfQqxvUk"},"source":["#### `nn.Sequential`\n","\n","[`nn.Sequential`](<https://pytorch.org/docs/stable/generated/torch.nn.Sequential.html>)은 순서를 갖는\n","모듈의 컨테이너이다. 데이터는 모듈들을 나열된 순서대로 통과한다. 순차 컨테이너(sequential container)를 사용하여 아래의 ``seq_modules``와 같은 신경망을 빠르게 만들 수 있다.\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Wk7N-sv8xvUk","colab":{"base_uri":"https://localhost:8080/"},"outputId":"824b5c93-7ee3-4252-9f37-7163cca86af2"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[-0.0333,  0.2017,  0.2365, -0.1200,  0.0542,  0.2103,  0.0135, -0.3470,\n","         -0.2061,  0.0491],\n","        [ 0.0039,  0.1499,  0.2371, -0.1485,  0.0523,  0.3345,  0.0496, -0.3788,\n","         -0.2201,  0.0369],\n","        [ 0.0689,  0.1479,  0.2206, -0.1252,  0.0388,  0.2189, -0.0534, -0.2929,\n","         -0.1407,  0.0749]], grad_fn=<AddmmBackward0>)"]},"metadata":{},"execution_count":24}],"source":["seq_modules = nn.Sequential(\n","    flatten, #28*28을 784로 평평하게\n","    layer1, #입력텐서에서 선형 변환을 수행하는 nn.linear의 인스턴스\n","    nn.ReLU(), #layer1의 출력에 relu함수를 요소별로 적용하는 활성화 함수\n","    nn.Linear(20, 10)#네트워크의 최종 출력을 생성하는 in_feature=20 및 out_feature=10인 선형레이어\n",")\n","#무작위 이미지 배치(28*28인 3대) 만들고 네트워크에 전달하여 (3,10) 형태의 텐서인 출력 로직을 얻음\n","input_images = torch.rand(3, 1, 28, 28)\n","logits = seq_modules(input_images)\n","logits"]},{"cell_type":"markdown","metadata":{"id":"m_jYETo_xvUl"},"source":["#### `nn.Softmax`\n","\n","신경망의 마지막 선형 계층은 [`nn.Softmax`](<https://pytorch.org/docs/stable/generated/torch.nn.Softmax.html>) 모듈에 전달될\n","[-\\infty, \\infty] 범위의 원시 값(raw value)인 `logits`를 반환한다. `nn.Softmax` 계층은 logits는 모델의 각 분류(class)에 대한 예측 확률을 나타내도록\n","[0, 1] 범위로 비례하여 조정(scale)한다. ``dim`` 매개변수는 값의 합이 1이 되는 차원을 나타낸다.\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MezKS9-bxvUl"},"outputs":[],"source":["#logits를 각 클래스의 예측 확률로 변환하는 softmax 함수를 logits 텐서에 적용\n","#nn.Softmax(dim=1) 함수는 softmax 작업이 수행될 차원을 지정하는 dim인수 사용 텐서의 2번째 차원을 따라 적용됨\n","softmax = nn.Softmax(dim=1)\n","pred_probab = softmax(logits)\n","#결과 텐서 pred_probab에는 입력 이미지에 대한 각 클래스의 예측 확률이 포함되며 \n","#각 행은 하나의 입력 이미지에 해당하고 각 열은 하나의 클래스에 해당\n","pred_probab"]},{"cell_type":"markdown","metadata":{"id":"QXRDL7r1dr0q"},"source":["**Note:** `SoftMax`함수 $\\sigma : R^K \\longrightarrow (0, 1)^K$의 정의: $\\sigma(z)_i = \\frac{e^{z_i}}{\\sum_{j=1}^K e^{z_j}}$"]},{"cell_type":"markdown","metadata":{"id":"_czY6AClxvUl"},"source":["모델 매개변수\n","------------------------------------------------------------------------------------------\n","\n","신경망에서 많은 계층들은 매개변수화(parameterize)되어 있다. 즉, 학습 중에 최적화되는 가중치(weight)와 편향(bias)을 가진다. ``nn.Module``을 상속하면 모델 객체 내부의 모든 필드들이 자동으로 추적(track)되며, 모델의 ``parameters()`` 및\n","``named_parameters()`` 메소드로 모든 매개변수에 접근할 수 있게 된다.\n","\n","이 예제에서는 각 매개변수들을 순회하며(iterate), 매개변수의 크기와 값을 출력한다.\n","\n","\n"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":295},"id":"JsRgYxQdxvUl","outputId":"a1a2dd57-fbfd-49c7-9885-4cacc239fb2d","executionInfo":{"status":"error","timestamp":1682238673644,"user_tz":-540,"elapsed":11,"user":{"displayName":"구한서 (hanseo)","userId":"04169580702962661413"}}},"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-2-9d15fb3786d6>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#모델의 구조와 해당 매개변수의 세부사항을 인쇄\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Model structure: {model}\\n\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#모델의 구조 표시 모델 객체의 named_parameters는 모델의 모든 매개변수 반복하고 이름,크기 및 처음 두값 인쇄하는데 사용\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#이는 매개변수 값이 올바르게 초기화 되었는지 확인하기 위해 수행\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"]}],"source":["#모델의 구조와 해당 매개변수의 세부사항을 인쇄\n","print(f\"Model structure: {model}\\n\\n\")\n","\n","#모델의 구조 표시 모델 객체의 named_parameters는 모델의 모든 매개변수 반복하고 이름,크기 및 처음 두값 인쇄하는데 사용\n","#이는 매개변수 값이 올바르게 초기화 되었는지 확인하기 위해 수행\n","for name, param in model.named_parameters(): \n","    print(f\"Layer: {name} | Size: {param.size()} | Values : {param[:2]} \\n\")\n","    # [:2] 슬라이스는 커질 수 있는 전체 텐서를 인쇄하지 않도록 각 텐서의 처음 두 값만 인쇄하는 데 사용됩니다.\n","    #fc1 레이어의 크기, 해당 레이어의 가중치 행렬 및 편향 벡터의 처음 두 값 인쇄\n","    #fc1.weight, fc1.bias, fc2.weight, fc2.bias, fc3.weight, fc3.bias"]},{"cell_type":"markdown","metadata":{"id":"HTbmC4EaxvUl"},"source":["------------------------------------------------------------------------------------------\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"kdVeExgOxvUm"},"source":["더 읽어보기\n","------------------------------------------------------------------------------------------\n","- [`torch.nn API`](<https://pytorch.org/docs/stable/nn.html>)\n","\n"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.13"}},"nbformat":4,"nbformat_minor":0}